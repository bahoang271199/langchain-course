{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 8.5: Advanced Agent Design Patterns with LangGraph\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous lessons, we built basic Agents with LangGraph and understood how they reason, act, and manage state. However, the real world often demands more sophisticated Agents capable of human interaction, handling complex situations, and even self-correction. This lesson will introduce **advanced Agent design patterns** with LangGraph, extending the capabilities of your LLM applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Human-in-the-Loop: Integrating Human Intervention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cases, an Agent should not operate completely autonomously. Human-in-the-Loop (HITL) intervention is necessary to:\n",
    "\n",
    "* **Validation:** Ensure the Agent makes correct decisions or actions before executing critical tasks (e.g., sending emails, performing financial transactions).\n",
    "* **Information Provision:** When the Agent lacks information or cannot retrieve it, it can ask the user to provide it.\n",
    "* **Correction:** When the Agent makes a mistake or enters an undesirable loop, a human can intervene to correct it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Human-in-the-Loop with LangGraph\n",
    "\n",
    "In LangGraph, you can implement HITL by:\n",
    "\n",
    "1.  **Adding a \"Human Review\" Node:** This Node will pause the Agent's flow and await input from a human.\n",
    "2.  **Conditional Edge:** After the \"Human Review\" Node, a Conditional Edge will decide the next flow based on human feedback (e.g., \"approved\" to continue, \"rejected\" to go back to a previous step, or \"provide_info\" to process new information).\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tool Calling: Handling Multiple Tool Calls and Result Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real-world Agents often need to use multiple tools in one reasoning turn or need to aggregate information from multiple sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Calling Multiple Tools in One Turn:** An LLM might decide to call multiple tools simultaneously if those tasks are independent or can run in parallel.\n",
    "    * **LangChain's `tool_calling_agent`:** Modern Agents in LangChain (e.g., `create_tool_calling_agent`) can automatically handle this if the LLM supports multi-tool calling (e.g., GPT-4, Gemini).\n",
    "    * **In LangGraph:** Your LLM Node will return a list of `AgentAction`s (if the LLM supports it), and your `call_tool` Node will need to be modified to execute all those actions and collect the results.\n",
    "* **Aggregating Results:** After calling multiple tools, the results (Observations) need to be aggregated and fed back to the LLM so it can generate a coherent final response. This is often done by adding all `ToolMessage`s to the `agent_scratchpad` or `chat_history` in the state.\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Self-Correction/Self-Healing Agents: Designing Agents that Automatically Detect and Fix Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self-correcting Agents are those capable of recognizing when they make mistakes or go off track, and automatically adjusting their behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Error Detection Mechanisms:**\n",
    "    * **Output Analysis:** The LLM can be instructed to analyze its own output or the output of tools to look for signs of errors (e.g., parsing errors, empty search results, irrelevant responses).\n",
    "    * **Condition Checks:** Conditional Nodes can be added to verify business constraints or data validity.\n",
    "* **Error Correction Mechanisms:**\n",
    "    * **Retry with Different Prompt:** If the LLM generates invalid output, it can be asked to retry with a refined prompt, providing more specific formatting instructions.\n",
    "    * **Retry with Different Tool:** If a tool fails, the Agent can try an alternative tool.\n",
    "    * **Change Strategy:** If one strategy is ineffective, the Agent can revert to the reasoning step and choose a different approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Self-Correction with LangGraph\n",
    "\n",
    "LangGraph is ideal for self-correction due to its looping and Conditional Edges capabilities:\n",
    "\n",
    "1.  **\"Error Detection\" Node:** A Node that checks the output of the previous Node.\n",
    "2.  **Conditional Edge:** If an error is detected, a conditional edge will route the flow to an \"Error Handling\" Node or back to the LLM Node with the error message in the state so the LLM can re-reason.\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multi-Agent Systems (Introduction): Concept of Multiple Agents Interacting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a problem is too large or complex for a single Agent, we can use a **Multi-Agent System**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Concept:** Multiple Agents (each potentially specializing in a specific domain or task) interact, collaborate, and communicate with each other to solve a larger problem.\n",
    "* **Roles:**\n",
    "    * **Task Delegation:** A primary Agent can delegate smaller tasks to specialized Agents.\n",
    "    * **Information Exchange:** Agents exchange information and intermediate results with each other.\n",
    "    * **Coordination:** Agents coordinate actions to achieve an overall goal.\n",
    "* **Applications:** Complex research, project planning, social simulations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Multi-Agent Systems with LangGraph\n",
    "\n",
    "LangGraph can be used to build multi-Agent systems by:\n",
    "\n",
    "1.  **Each Agent as a Subgraph:** Each Agent can be an independent LangGraph graph.\n",
    "2.  **\"Delegate\" Node:** A Node in one Agent's graph can call another Agent's graph.\n",
    "3.  **Shared State/Communication:** Agents can communicate by updating a common state or through message passing mechanisms.\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Practical Example: Building a More Complex Agent with Self-Correction Capabilities or Human Confirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will extend the Agent from Lesson 8.4 to add a simple self-correction capability: if the LLM attempts to call a non-existent tool, the Agent will recognize the error and attempt to correct its action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparation:**\n",
    "* Ensure you have the necessary libraries installed: `langchain-openai`, `google-search-results`, `numexpr`, `langgraph`.\n",
    "* Set the `OPENAI_API_KEY` and `SERPAPI_API_KEY` environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries if not already installed\n",
    "# pip install langchain-openai openai google-search-results numexpr langgraph\n",
    "\n",
    "import os\n",
    "from typing import TypedDict, Annotated, List, Union, Dict, Any\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "import operator\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from langchain.tools import Tool\n",
    "from langchain_community.tools.calculator.tool import Calculator\n",
    "from langchain_core.agents import AgentFinish, AgentAction # To parse LLM output\n",
    "\n",
    "# Thiết lập biến môi trường cho khóa API của OpenAI và SerpAPI\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n",
    "# os.environ[\"SERPAPI_API_KEY\"] = \"YOUR_SERPAPI_API_KEY\"\n",
    "\n",
    "# --- 1. Định nghĩa kiểu trạng thái cho đồ thị Agent ---\n",
    "class AgentState(TypedDict):\n",
    "    chat_history: Annotated[List[BaseMessage], operator.add]\n",
    "    intermediate_steps: Annotated[List[Union[AgentAction, ToolMessage]], operator.add]\n",
    "    # Thêm trường để theo dõi số lần thử lại (cho self-correction)\n",
    "    retry_count: int\n",
    "\n",
    "# --- 2. Khởi tạo LLM và Tools ---\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "search_tool = Tool(\n",
    "    name=\"Google Search\",\n",
    "    func=SerpAPIWrapper().run,\n",
    "    description=\"Hữu ích khi bạn cần tìm kiếm thông tin trên Google về các sự kiện hiện tại hoặc dữ liệu thực tế.\" # Useful when you need to search for information on Google about current events or factual data.\n",
    ")\n",
    "calculator_tool = Calculator()\n",
    "tools = [search_tool, calculator_tool]\n",
    "\n",
    "# --- 3. Định nghĩa Prompt cho Agent ---\n",
    "agent_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Bạn là một trợ lý hữu ích. Bạn có quyền truy cập vào các công cụ sau: {tools}. Sử dụng chúng để trả lời các câu hỏi của người dùng. Nếu bạn đã có câu trả lời cuối cùng, hãy trả lời trực tiếp. Nếu bạn gặp lỗi với một công cụ, hãy thử lại hoặc thử một cách tiếp cận khác.\"), # You are a helpful assistant. You have access to the following tools: {tools}. Use them to answer user questions. If you have a final answer, respond directly. If you encounter an error with a tool, try again or try a different approach.\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "# --- 4. Định nghĩa các Node của đồ thị ---\n",
    "\n",
    "# Node 1: Call LLM (phần suy luận/hành động của ReAct)\n",
    "def call_llm_node(state: AgentState) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Node này gọi LLM để suy luận về bước tiếp theo.\n",
    "    LLM có thể quyết định gọi Tool hoặc đưa ra câu trả lời cuối cùng.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Node: Call LLM (Suy luận/Hành động) ---\") # --- Node: Call LLM (Reasoning/Acting) ---\n",
    "    messages = agent_prompt.format_messages(\n",
    "        tools=tools,\n",
    "        chat_history=state[\"chat_history\"],\n",
    "        agent_scratchpad=state[\"intermediate_steps\"]\n",
    "    )\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    if \"Final Answer:\" in response.content:\n",
    "        final_answer_content = response.content.split(\"Final Answer:\", 1)[1].strip()\n",
    "        return {\"chat_history\": [AIMessage(content=final_answer_content)], \"intermediate_steps\": [AgentFinish(return_values={\"output\": final_answer_content}, log=response.content)]}\n",
    "    \n",
    "    try:\n",
    "        # Cải thiện phân tích AgentAction một chút\n",
    "        # Đây vẫn là một điểm yếu nếu LLM không tuân thủ định dạng chính xác.\n",
    "        # Trong thực tế, bạn có thể dùng LangChain's AgentOutputParser.\n",
    "        thought_part = \"\"\n",
    "        action_part = \"\"\n",
    "        action_input_part = \"\"\n",
    "\n",
    "        if \"Thought:\" in response.content:\n",
    "            parts = response.content.split(\"Thought:\", 1)\n",
    "            thought_part = parts[1].split(\"Action:\", 1)[0].strip() if \"Action:\" in parts[1] else parts[1].strip()\n",
    "        \n",
    "        if \"Action:\" in response.content:\n",
    "            parts = response.content.split(\"Action:\", 1)[1].split(\"Action Input:\", 1)\n",
    "            action_part = parts[0].strip()\n",
    "            action_input_part = parts[1].strip() if len(parts) > 1 else \"\"\n",
    "\n",
    "        action = AgentAction(tool=action_part, tool_input=action_input_part, log=response.content)\n",
    "        print(f\"  LLM quyết định hành động: Tool='{action.tool}', Input='{action.tool_input}'\") # LLM decides to act:\n",
    "        return {\"intermediate_steps\": [action]}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Lỗi phân tích đầu ra LLM thành Action: {e}. Phản hồi LLM: {response.content}\") # Error parsing LLM output to Action:\n",
    "        # Nếu LLM trả về định dạng không thể phân tích, chúng ta sẽ coi đây là một lỗi\n",
    "        # và cập nhật retry_count, sau đó quay lại LLM để nó tự sửa.\n",
    "        return {\n",
    "            \"chat_history\": [AIMessage(content=f\"Lỗi phân tích phản hồi của tôi. Vui lòng thử lại.\")], # Error parsing my response. Please try again.\n",
    "            \"intermediate_steps\": [AgentFinish(return_values={\"output\": \"LLM parsing error\"}, log=response.content)],\n",
    "            \"retry_count\": state.get(\"retry_count\", 0) + 1 # Tăng số lần thử lại # Increment retry count\n",
    "        }\n",
    "\n",
    "\n",
    "# Node 2: Call Tool (phần hành động của ReAct)\n",
    "def call_tool_node(state: AgentState) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Node này thực thi Tool mà LLM đã quyết định.\n",
    "    Bao gồm logic xử lý lỗi Tool và cập nhật retry_count.\n",
    "    \"\"\"\n",
    "    print(\"--- Node: Call Tool (Thực thi công cụ) ---\") # --- Node: Call Tool (Execute tool) ---\n",
    "    last_action = state[\"intermediate_steps\"][-1]\n",
    "    \n",
    "    tool_name = last_action.tool\n",
    "    tool_input = last_action.tool_input\n",
    "\n",
    "    selected_tool = next((t for t in tools if t.name == tool_name), None)\n",
    "    if selected_tool:\n",
    "        try:\n",
    "            tool_output = selected_tool.run(tool_input)\n",
    "            print(f\"  Tool '{tool_name}' trả về: {tool_output[:100]}...\") # Tool '{tool_name}' returns:\n",
    "            return {\"intermediate_steps\": [ToolMessage(content=tool_output, tool_call_id=last_action.tool)], \"retry_count\": 0} # Reset retry_count khi thành công # Reset retry_count on success\n",
    "        except Exception as e:\n",
    "            error_message = f\"Lỗi khi thực thi Tool '{tool_name}' với đầu vào '{tool_input}': {e}\" # Error executing Tool '{tool_name}' with input '{tool_input}':\n",
    "            print(f\"  {error_message}\")\n",
    "            # Nếu Tool thất bại, trả về lỗi và tăng retry_count\n",
    "            return {\"intermediate_steps\": [ToolMessage(content=error_message, tool_call_id=last_action.tool)], \"retry_count\": state.get(\"retry_count\", 0) + 1} # If Tool fails, return error and increment retry_count\n",
    "    else:\n",
    "        # Nếu Tool không tồn tại, đây là một lỗi mà LLM cần tự sửa\n",
    "        error_message = f\"Lỗi: Không tìm thấy Tool có tên '{tool_name}'. Vui lòng kiểm tra lại tên công cụ.\" # Error: Tool with name '{tool_name}' not found. Please check tool name again.\n",
    "        print(f\"  {error_message}\")\n",
    "        return {\"intermediate_steps\": [ToolMessage(content=error_message, tool_call_id=\"unknown_tool\")], \"retry_count\": state.get(\"retry_count\", 0) + 1} # If Tool does not exist, this is an error that LLM needs to self-correct\n",
    "\n",
    "# --- 5. Định nghĩa hàm điều kiện cho Conditional Edge (quyết định tiếp tục vòng lặp hay kết thúc) ---\n",
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    Hàm này kiểm tra bước trung gian cuối cùng và retry_count để quyết định luồng tiếp theo.\n",
    "    \"\"\"\n",
    "    last_step = state[\"intermediate_steps\"][-1]\n",
    "    retry_count = state.get(\"retry_count\", 0)\n",
    "    \n",
    "    MAX_RETRIES = 2 # Số lần thử lại tối đa # Max retries\n",
    "\n",
    "    if isinstance(last_step, AgentFinish):\n",
    "        print(\"--- Quyết định: KẾT THÚC (AgentFinish) ---\") # --- Decision: END (AgentFinish) ---\n",
    "        return \"end\"\n",
    "    elif isinstance(last_step, AgentAction):\n",
    "        # Nếu LLM đưa ra một Action, chúng ta sẽ gọi Tool\n",
    "        print(\"--- Quyết định: TIẾP TỤC (AgentAction) ---\") # --- Decision: CONTINUE (AgentAction) ---\n",
    "        return \"continue\"\n",
    "    elif isinstance(last_step, ToolMessage):\n",
    "        # Nếu bước cuối cùng là một ToolMessage (tức là kết quả của Tool)\n",
    "        # và có lỗi (retry_count > 0), quay lại LLM để tự sửa\n",
    "        if \"Lỗi\" in last_step.content or retry_count > 0: # Kiểm tra nội dung lỗi hoặc retry_count # Check error content or retry_count\n",
    "            print(f\"--- Quyết định: TỰ SỬA LỖI (ToolMessage lỗi, thử lại lần {retry_count}) ---\") # --- Decision: SELF-CORRECT (ToolMessage error, retry attempt {retry_count}) ---\n",
    "            if retry_count >= MAX_RETRIES:\n",
    "                print(\"--- Đã đạt số lần thử lại tối đa. KẾT THÚC ---\") # --- Max retries reached. END ---\n",
    "                return \"end\" # Kết thúc nếu quá nhiều lần thử lại # End if too many retries\n",
    "            return \"call_llm\" # Quay lại LLM để nó suy nghĩ lại # Return to LLM to re-reason\n",
    "        else:\n",
    "            # Nếu ToolMessage thành công, quay lại LLM để tổng hợp hoặc kết thúc\n",
    "            print(\"--- Quyết định: TIẾP TỤC (ToolMessage thành công) ---\") # --- Decision: CONTINUE (ToolMessage successful) ---\n",
    "            return \"call_llm\"\n",
    "    else:\n",
    "        print(f\"--- Quyết định: LỖI/KHÔNG XÁC ĐỊNH (Kiểu không mong muốn: {type(last_step)}) ---\") # --- Decision: ERROR/UNKNOWN (Unexpected type:\n",
    "        return \"end\"\n",
    "\n",
    "# --- 6. Xây dựng đồ thị Agent ---\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Thêm các Node\n",
    "workflow.add_node(\"call_llm\", call_llm_node)\n",
    "workflow.add_node(\"call_tool\", call_tool_node)\n",
    "\n",
    "# Đặt điểm bắt đầu: Luôn bắt đầu bằng việc gọi LLM để suy luận\n",
    "workflow.set_entry_point(\"call_llm\")\n",
    "\n",
    "# Định nghĩa cạnh có điều kiện từ Node LLM\n",
    "workflow.add_conditional_edges(\n",
    "    \"call_llm\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"call_tool\",\n",
    "        \"end\": END,\n",
    "        \"call_llm\": \"call_llm\" # Thêm cạnh này để LLM có thể tự gọi lại chính nó nếu cần tự sửa lỗi phân tích # Add this edge so LLM can call itself again if it needs to self-correct parsing errors\n",
    "    }\n",
    ")\n",
    "\n",
    "# Định nghĩa cạnh từ Node Tool quay trở lại Node LLM\n",
    "workflow.add_edge(\"call_tool\", \"call_llm\")\n",
    "\n",
    "# Biên dịch đồ thị\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"\\n--- Bắt đầu thực hành Agent với khả năng tự sửa lỗi ---\") # --- Starting Agent with self-correction capabilities ---\n",
    "\n",
    "# --- Tình huống 1: Câu hỏi cần tìm kiếm và tính toán (bình thường) ---\n",
    "print(\"\\n--- Tình huống 1: Câu hỏi cần tìm kiếm và tính toán (bình thường) ---\") # --- Scenario 1: Question requires search and calculation (normal) ---\n",
    "initial_state_1 = {\"chat_history\": [HumanMessage(content=\"Thời tiết hôm nay ở London là bao nhiêu độ C? Sau đó nhân kết quả với 2.\")], \"intermediate_steps\": [], \"retry_count\": 0} # What is the weather like today in London in Celsius? Then multiply the result by 2.\n",
    "final_state_1 = app.invoke(initial_state_1)\n",
    "print(f\"\\nPhản hồi cuối cùng:\") # Final response:\n",
    "for message in final_state_1[\"chat_history\"]:\n",
    "    print(f\"{message.type.capitalize()}: {message.content}\")\n",
    "\n",
    "# --- Tình huống 2: LLM cố gắng gọi một công cụ không tồn tại (tự sửa lỗi) ---\n",
    "print(\"\\n--- Tình huống 2: LLM cố gắng gọi một công cụ không tồn tại (tự sửa lỗi) ---\") # --- Scenario 2: LLM attempts to call a non-existent tool (self-correction) ---\n",
    "# Để mô phỏng, chúng ta sẽ tạm thời thay đổi prompt để LLM cố tình gọi một tool sai\n",
    "original_prompt = agent_prompt\n",
    "agent_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Bạn là một trợ lý hữu ích. Bạn có quyền truy cập vào các công cụ sau: {tools}. Sử dụng chúng để trả lời các câu hỏi của người dùng. Nếu bạn đã có câu trả lời cuối cùng, hãy trả lời trực tiếp. Cố gắng sử dụng công cụ 'NonExistentTool' nếu bạn không chắc chắn.\"), # Intentionally make LLM try a wrong tool\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])\n",
    "# Cần biên dịch lại app sau khi thay đổi prompt\n",
    "agent = create_react_agent(llm, tools, agent_prompt)\n",
    "app = StateGraph(AgentState)\n",
    "app.add_node(\"call_llm\", call_llm_node)\n",
    "app.add_node(\"call_tool\", call_tool_node)\n",
    "app.set_entry_point(\"call_llm\")\n",
    "app.add_conditional_edges(\"call_llm\", should_continue, {\"continue\": \"call_tool\", \"end\": END, \"call_llm\": \"call_llm\"})\n",
    "app.add_edge(\"call_tool\", \"call_llm\")\n",
    "app = app.compile()\n",
    "\n",
    "initial_state_2 = {\"chat_history\": [HumanMessage(content=\"Hãy nói về LangChain.\")], \"intermediate_steps\": [], \"retry_count\": 0} # Tell me about LangChain.\n",
    "final_state_2 = app.invoke(initial_state_2)\n",
    "print(f\"\\nPhản hồi cuối cùng:\") # Final response:\n",
    "for message in final_state_2[\"chat_history\"]:\n",
    "    print(f\"{message.type.capitalize()}: {message.content}\")\n",
    "\n",
    "# Khôi phục prompt gốc\n",
    "agent_prompt = original_prompt\n",
    "agent = create_react_agent(llm, tools, agent_prompt)\n",
    "app = StateGraph(AgentState)\n",
    "app.add_node(\"call_llm\", call_llm_node)\n",
    "app.add_node(\"call_tool\", call_tool_node)\n",
    "app.set_entry_point(\"call_llm\")\n",
    "app.add_conditional_edges(\"call_llm\", should_continue, {\"continue\": \"call_tool\", \"end\": END, \"call_llm\": \"call_llm\"})\n",
    "app.add_edge(\"call_tool\", \"call_llm\")\n",
    "app = app.compile()\n",
    "\n",
    "print(\"\\n--- Kết thúc thực hành Agent với khả năng tự sửa lỗi ---\") # --- End of Agent with self-correction capabilities practical ---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
  "nbformat": 4,
  "nbformat_minor": 5
}
