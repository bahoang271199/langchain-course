{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1.4: Setting up the Environment and \"Hello World\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin developing applications with LangChain, setting up a suitable working environment is the first and most crucial step. This lesson will guide you through installing the necessary tools and running your first LangChain program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installing Python and the Pip Package Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python** is the primary programming language used with LangChain. **Pip** is the default package manager for Python, helping you install and manage necessary libraries (packages)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Installing Python\n",
    "\n",
    "* **Check if Python is already installed:** Open Terminal (on macOS/Linux) or Command Prompt/PowerShell (on Windows) and type:\n",
    "    ```bash\n",
    "    python --version\n",
    "    # Or\n",
    "    python3 --version\n",
    "    ```\n",
    "    If you see a version number (e.g., `Python 3.9.12`), Python is installed. LangChain requires Python 3.8 or higher.\n",
    "\n",
    "* **If not installed:**\n",
    "    * **Windows:** Visit the official Python website ([https://www.python.org/downloads/](https://www.python.org/downloads/)), download the installer for Windows, and follow the instructions. **Make sure to select the \"Add Python to PATH\" option during installation.**\n",
    "    * **macOS:** Python is often pre-installed. If a newer version is needed, you can install it via Homebrew: `brew install python`.\n",
    "    * **Linux:** Python is also usually available. To install a specific version, use your operating system's package manager (e.g., `sudo apt-get install python3.9` on Ubuntu)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Checking Pip\n",
    "\n",
    "* Pip is usually installed along with Python 3.4 and later. To check:\n",
    "    ```bash\n",
    "    pip --version\n",
    "    # Or\n",
    "    pip3 --version\n",
    "    ```\n",
    "    If you see a version number (e.g., `pip 23.0.1`), Pip is ready.\n",
    "\n",
    "* **If Pip is missing:** You might need to reinstall Python or run the following command (on Linux/macOS):\n",
    "    ```bash\n",
    "    python3 -m ensurepip --default-pip\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating a Virtual Environment and Managing Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using virtual environments is a good practice in Python development. It helps isolate project-specific libraries, preventing version conflicts between different projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Why Virtual Environments?\n",
    "\n",
    "* **Dependency Isolation:** Each project can have different library version requirements. A virtual environment ensures that libraries from Project A do not interfere with Project B.\n",
    "* **Clean and Manageable:** When you install libraries into a virtual environment, they only exist within that environment, not polluting your system's global Python installation.\n",
    "* **Easy Sharing:** You can easily share the list of required libraries for your project with others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Creating and Activating a Virtual Environment\n",
    "\n",
    "We will use the `venv` module, which is built into Python.\n",
    "\n",
    "1.  **Create a project directory:**\n",
    "    ```bash\n",
    "    mkdir langchain_course\n",
    "    cd langchain_course\n",
    "    ```\n",
    "\n",
    "2.  **Create the virtual environment:**\n",
    "    ```bash\n",
    "    python3 -m venv venv_langchain\n",
    "    ```\n",
    "    This command will create a directory named `venv_langchain` (you can choose a different name) containing a copy of Python and Pip.\n",
    "\n",
    "3.  **Activate the virtual environment:**\n",
    "    * **macOS/Linux:**\n",
    "        ```bash\n",
    "        source venv_langchain/bin/activate\n",
    "        ```\n",
    "    * **Windows (Command Prompt):**\n",
    "        ```cmd\n",
    "        venv_langchain\\Scripts\\activate.bat\n",
    "        ```\n",
    "    * **Windows (PowerShell):**\n",
    "        ```powershell\n",
    "        .\\venv_langchain\\Scripts\\Activate.ps1\n",
    "        ```\n",
    "    Once activated, you will see the virtual environment's name (e.g., `(venv_langchain)`) appear at the beginning of your command prompt. This indicates you are working within the virtual environment.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Managing Dependencies\n",
    "\n",
    "* **Installing Libraries:** When the virtual environment is activated, any libraries you install using `pip` will be installed into that environment.\n",
    "    ```bash\n",
    "    (venv_langchain) pip install <library_name>\n",
    "    ```\n",
    "\n",
    "* **Storing Dependencies:** To share your project or recreate the environment, you should save the list of installed libraries to a `requirements.txt` file:\n",
    "    ```bash\n",
    "    (venv_langchain) pip freeze > requirements.txt\n",
    "    ```\n",
    "\n",
    "* **Installing from `requirements.txt`:** Others (or you later) can easily install all necessary libraries using:\n",
    "    ```bash\n",
    "    (venv_langchain) pip install -r requirements.txt\n",
    "    ```\n",
    "\n",
    "* **Deactivating the Virtual Environment:** When you are done working, you can exit the virtual environment:\n",
    "    ```bash\n",
    "    (venv_langchain) deactivate\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Installing LangChain and Related Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the virtual environment is set up and activated, we will install the libraries needed for LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  **Install LangChain:**\n",
    "    ```bash\n",
    "    (venv_langchain) pip install langchain\n",
    "    ```\n",
    "\n",
    "2.  **Install Integrations with LLM Providers (e.g., OpenAI, Google Generative AI):**\n",
    "    You need to install the corresponding integration package for the LLM you want to use.\n",
    "\n",
    "    * **If using OpenAI:**\n",
    "        ```bash\n",
    "        (venv_langchain) pip install langchain-openai openai\n",
    "        ```\n",
    "    * **If using Google Generative AI (Gemini):**\n",
    "        ```bash\n",
    "        (venv_langchain) pip install langchain-google-genai google-generativeai\n",
    "        ```\n",
    "    * **If using Hugging Face Hub (for open-source models):**\n",
    "        ```bash\n",
    "        (venv_langchain) pip install langchain-huggingface transformers\n",
    "        ```\n",
    "\n",
    "    *Note:* In this course, we will frequently use both OpenAI and Google Gemini for examples. You can install both if you wish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setting Up and Managing API Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interact with paid LLMs (like OpenAI GPT, Google Gemini), you need an API Key. Securely managing API keys is extremely important. **Never embed API keys directly into your source code.**\n",
    "\n",
    "The best practice is to use **environment variables**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Obtaining API Keys\n",
    "\n",
    "* **OpenAI:** Log in to your OpenAI account, navigate to the API keys section ([https://platform.openai.com/api-keys](https://platform.openai.com/api-keys)), and create a new key.\n",
    "* **Google Gemini:** Visit Google AI Studio ([https://aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey)), log in, and create a new API key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Setting Environment Variables\n",
    "\n",
    "* **macOS/Linux (temporary for current session):**\n",
    "    ```bash\n",
    "    export OPENAI_API_KEY=\"sk-YOUR_OPENAI_API_KEY\"\n",
    "    export GOOGLE_API_KEY=\"YOUR_GOOGLE_API_KEY\"\n",
    "    ```\n",
    "    *Note:* These variables will be lost when you close the Terminal.\n",
    "\n",
    "* **macOS/Linux (permanent - add to `.bashrc`, `.zshrc`, or `.profile`):**\n",
    "    Open your shell configuration file (e.g., `~/.bashrc` or `~/.zshrc`) with a text editor and add the lines above to the end of the file. Then, run `source ~/.bashrc` (or `.zshrc`) to apply the changes.\n",
    "\n",
    "* **Windows (Command Prompt - temporary):**\n",
    "    ```cmd\n",
    "    set OPENAI_API_KEY=\"sk-YOUR_OPENAI_API_KEY\"\n",
    "    set GOOGLE_API_KEY=\"YOUR_GOOGLE_API_KEY\"\n",
    "    ```\n",
    "\n",
    "* **Windows (PowerShell - temporary):**\n",
    "    ```powershell\n",
    "    $env:OPENAI_API_KEY=\"sk-YOUR_OPENAI_API_KEY\"\n",
    "    $env:GOOGLE_API_KEY=\"YOUR_GOOGLE_API_KEY\"\n",
    "    ```\n",
    "\n",
    "* **Windows (permanent - via GUI):**\n",
    "    * Search for \"Edit the system environment variables\" in the Start Menu.\n",
    "    * Click on \"Environment Variables...\".\n",
    "    * Under \"User variables for <Your_Username>\", click \"New...\" to add a new variable (e.g., `OPENAI_API_KEY` with your API key value)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Using Environment Variables in Python\n",
    "\n",
    "LangChain and its integration libraries will automatically look for API keys in environment variables. You just need to import the `os` library and access them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check if environment variables are set\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "google_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if openai_key:\n",
    "    print(\"OPENAI_API_KEY is set.\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY is NOT set. Please set the environment variable.\")\n",
    "\n",
    "if google_key:\n",
    "    print(\"GOOGLE_API_KEY is set.\")\n",
    "else:\n",
    "    print(\"GOOGLE_API_KEY is NOT set. Please set the environment variable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Writing Your First \"Hello World\" Program with LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our environment is ready and API keys are set up, let's write our first LangChain program to send a simple prompt and get a response from an LLM.\n",
    "\n",
    "We will use `ChatOpenAI` (or `ChatGoogleGenerativeAI`) as it is the modern and flexible approach for most tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  **Create a new Python file** (e.g., `hello_langchain.py`) in your project directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  **Write the code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hello_langchain.py\n",
    "\n",
    "import os\n",
    "# Import ChatOpenAI if you are using OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "# Import ChatGoogleGenerativeAI if you are using Google Gemini\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# --- 1. Initialize LLM (choose one) ---\n",
    "\n",
    "# Use OpenAI Chat Model\n",
    "# Make sure you have 'langchain-openai' installed and OPENAI_API_KEY environment variable set\n",
    "llm = None\n",
    "try:\n",
    "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "    print(\"ChatOpenAI initialized.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not initialize ChatOpenAI: {e}. Please check installation and API key.\")\n",
    "    # Try initializing Google Gemini if OpenAI fails\n",
    "    try:\n",
    "        # Make sure you have 'langchain-google-genai' installed and GOOGLE_API_KEY environment variable set\n",
    "        llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.7)\n",
    "        print(\"ChatGoogleGenerativeAI initialized.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not initialize ChatGoogleGenerativeAI: {e}. Please check installation and API key.\")\n",
    "        print(\"No LLM initialized successfully. Please check your environment.\")\n",
    "        exit() # Exit if no LLM works\n",
    "\n",
    "# --- 2. Define Prompt Template ---\n",
    "# Use ChatPromptTemplate to define roles (system, human)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"You are a helpful AI assistant.\"),\n",
    "    HumanMessage(content=\"Tell a short story about a {animal} that can {action}.\"),\n",
    "])\n",
    "\n",
    "# --- 3. Define Output Parser ---\n",
    "# StrOutputParser will extract the string content from the LLM's response\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# --- 4. Build the Chain ---\n",
    "# Use LCEL (LangChain Expression Language) to connect components\n",
    "# prompt | llm | output_parser forms a simple pipeline\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "# --- 5. Execute the Chain and get response ---\n",
    "print(\"\\nSending prompt to LLM...\")\n",
    "response = chain.invoke({\"animal\": \"dog\", \"action\": \"talk\"})\n",
    "\n",
    "print(\"\\n--- Response from LLM ---\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.  **Run the program:**\n",
    "    Ensure your virtual environment is activated and you are in your project directory.\n",
    "    ```bash\n",
    "    (venv_langchain) python hello_langchain.py\n",
    "    ```\n",
    "\n",
    "    You should see output similar to this (LLM response will vary):\n",
    "    ```\n",
    "    ChatOpenAI initialized.\n",
    "\n",
    "    Sending prompt to LLM...\n",
    "\n",
    "    --- Response from LLM ---\n",
    "    Once upon a time, there was a dog named Buddy. Buddy was not like other dogs; he had an amazing secret: he could talk! Not just bark or growl, but speak in clear, articulate words.\n",
    "    ... (story continues) ...\n",
    "    ```\n",
    "\n",
    "Congratulations! You have successfully set up your environment and run your first LangChain application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Summary\n",
    "\n",
    "This lesson provided a detailed guide on setting up the development environment for LangChain. We started by ensuring **Python and Pip** are correctly installed. Next, the importance of using **virtual environments (`venv`)** was emphasized for efficient dependency management, along with steps to create and activate them. We then proceeded to install the **LangChain library** and its integration packages for LLM providers. Another crucial part was **setting up and managing API keys** securely using environment variables. Finally, we wrote and ran our first **\"Hello World\" program with LangChain**, using `ChatPromptTemplate`, `ChatModel`, and `StrOutputParser` to create a simple chain, illustrating how core components work together."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
