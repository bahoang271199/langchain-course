{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1.1: Overview of LLMs and Generative AI\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Artificial Intelligence (AI) and Machine Learning (ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Artificial Intelligence (AI)\n",
    "\n",
    "**Artificial Intelligence (AI)** is a broad field of computer science focused on creating systems or machines capable of performing tasks that typically require human intelligence. The goal of AI is to enable machines to reason, learn, problem-solve, perceive, understand language, and even create.\n",
    "\n",
    "* **Historical Development:** AI originated in the 1950s, with initial ideas about machines that could \"think.\" Through various periods of \"AI winters\" and \"AI springs,\" the field has seen a strong surge in recent years, thanks to the development of big data, computational power, and new algorithms.\n",
    "\n",
    "* **Main Branches of AI:**\n",
    "    * **Narrow AI (Weak AI):** Designed to perform a specific task (e.g., playing chess, speech recognition, recommendation systems). Most current AI falls into this category.\n",
    "    * **General AI (Strong AI):** Capable of performing any intellectual task that a human can. This remains a long-term research goal.\n",
    "    * **Super AI:** Surpasses human intelligence in all aspects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Machine Learning (ML)\n",
    "\n",
    "**Machine Learning (ML)** is a subset of AI that focuses on developing algorithms that allow computers to learn from data without being explicitly programmed. Instead of writing rigid rules, we provide the model with data and enable it to automatically discover patterns and relationships.\n",
    "\n",
    "* **Relationship between AI and ML:** ML is a core method for achieving AI. Many modern AI applications are built upon machine learning techniques.\n",
    "\n",
    "* **Basic Types of Machine Learning:**\n",
    "    * **Supervised Learning:** Learning from labeled data (input-output pairs). Examples: spam email classification, house price prediction.\n",
    "    * **Unsupervised Learning:** Discovering hidden patterns or structures in unlabeled data. Examples: customer clustering, dimensionality reduction.\n",
    "    * **Reinforcement Learning:** Learning through interaction with an environment, receiving rewards or penalties. Examples: playing games, robot control.\n",
    "    * **Deep Learning (DL):** A subset of ML that uses artificial neural networks with many layers (deep neural networks) to learn complex representations from data. DL is a key driver for the recent AI boom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Concept of Generative AI and its Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. What is Generative AI?\n",
    "\n",
    "**Generative AI** is a type of artificial intelligence capable of **creating new content** (text, images, audio, video, code, etc.) rather than merely analyzing or classifying existing data. Generative AI models learn patterns and structures from a large dataset, then use this knowledge to produce new, unique examples that are still realistic and consistent with the training data.\n",
    "\n",
    "* **Difference from Discriminative AI:**\n",
    "    * **Discriminative AI:** Learns to distinguish between different types of data (e.g., classifying dog/cat, spam detection).\n",
    "    * **Generative AI:** Learns to create new data similar to the training data (e.g., generating new dog/cat images, writing emails).\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Importance of Generative AI\n",
    "\n",
    "Generative AI is revolutionizing many industries and fields due to its extraordinary creative capabilities:\n",
    "\n",
    "* **Content Creation:** Writing articles, scripting, composing music, graphic design, video generation.\n",
    "* **Software Development:** Code generation, debugging, documentation creation.\n",
    "* **Scientific Research:** Discovering new drugs, designing materials.\n",
    "* **Education:** Creating personalized learning materials.\n",
    "* **Customer Service:** Smarter chatbots, automated support.\n",
    "* **Product Design:** Generating new design ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. What are Large Language Models (LLMs)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Definition\n",
    "\n",
    "**Large Language Models (LLMs)** are a type of generative AI model trained on an enormous amount of text data (billions to trillions of words) from the internet, books, articles, etc. The primary goal of LLMs is to understand and generate human natural language. They are capable of performing various language-related tasks such as:\n",
    "\n",
    "* Text Generation\n",
    "* Translation\n",
    "* Summarization\n",
    "* Question Answering\n",
    "* Text Completion\n",
    "* Reasoning\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Key Characteristics of LLMs\n",
    "\n",
    "* **Large Scale:** Both in terms of the number of parameters (billions to trillions) and the amount of training data. This scale allows them to learn complex language patterns.\n",
    "* **Generalization Capability:** After being trained on a diverse dataset, LLMs can perform various tasks without specific retraining for each task (zero-shot, few-shot learning).\n",
    "* **Emergent Abilities:** Some capabilities (such as reasoning, problem-solving) only appear when the model reaches a certain scale, which cannot be predicted from smaller models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Basic Architecture of LLMs (Transformer, Attention Mechanism - Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most modern LLMs are based on the **Transformer** architecture, introduced by Google in 2017 in the paper \"Attention Is All You Need.\" The Transformer revolutionized natural language processing (NLP) thanks to its Attention mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Transformer Architecture\n",
    "\n",
    "The Transformer consists of two main parts:\n",
    "* **Encoder:** Processes the input sequence and generates contextual representations.\n",
    "* **Decoder:** Uses the representation from the Encoder to generate the output sequence.\n",
    "\n",
    "\n",
    "\n",
    "In generative LLMs like GPT, the architecture typically focuses on the Decoder part of the Transformer, allowing the model to generate text token by token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Attention Mechanism\n",
    "\n",
    "The **Attention mechanism** is the heart of the Transformer. It allows the model to focus on different parts of the input sequence when processing a specific part of that sequence. This solves the problem that previous sequential models (like RNN, LSTM) faced when dealing with long sequences, where information at the beginning of the sequence could be lost.\n",
    "\n",
    "* **How it works (simplified):** When the model generates a word, it will \"look back\" at all previous words in the sentence (or even the entire input text) and assign weights to how relevant each of those words is to the current word being generated. This allows the model to understand the context better.\n",
    "\n",
    "* **Example:** In the sentence \"The cat sat on the mat,\" when the model processes the word \"mat,\" the attention mechanism helps it recognize that \"mat\" has a strong relationship with \"sat\" and \"cat,\" allowing the model to better understand the context.\n",
    "\n",
    "* **Self-Attention:** A crucial variant that allows the model to consider the relationships between different words within the same input sequence to create a richer representation for each word.\n",
    "\n",
    "Although we don't delve into complex mathematics, understanding that Transformer and Attention are fundamental components that help LLMs process and generate language effectively is crucial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Popular LLM Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LLM market is rapidly evolving with many powerful models from various providers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. OpenAI GPT (Generative Pre-trained Transformer)\n",
    "\n",
    "* **Developer:** OpenAI.\n",
    "* **Characteristics:** One of the pioneering and most famous LLM families. Known for its high-quality text generation, contextual understanding, and diverse task performance.\n",
    "* **Notable Versions:**\n",
    "    * **GPT-3.5:** A popular model, widely used in ChatGPT.\n",
    "    * **GPT-4:** A more powerful version, with better reasoning capabilities, multimodal input processing (e.g., images), and higher accuracy.\n",
    "* **Usage Example (Python):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install OpenAI library if not already installed: pip install openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# Set up API key (replace with your actual API key)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def get_gpt_response(prompt_text):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\", # Or \"gpt-4\" if you have access\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt_text}\n",
    "            ],\n",
    "            max_tokens=150,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "# Usage example\n",
    "prompt = \"Write a short paragraph about the benefits of artificial intelligence.\"\n",
    "print(get_gpt_response(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Google Gemini\n",
    "\n",
    "* **Developer:** Google.\n",
    "* **Characteristics:** Google's latest family of multimodal models, designed to understand and operate across various data types (text, images, audio, video). Available in versions optimized for different tasks and scales (Ultra, Pro, Nano).\n",
    "* **Usage Example (Python):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Google Generative AI library if not already installed: pip install -q google-generativeai\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# Set up API key (replace with your actual API key)\n",
    "# genai.configure(api_key=\"YOUR_GOOGLE_API_KEY\")\n",
    "\n",
    "def get_gemini_response(prompt_text):\n",
    "    try:\n",
    "        model = genai.GenerativeModel('gemini-pro') # Or 'gemini-ultra' if you have access\n",
    "        response = model.generate_content(prompt_text)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "# Usage example\n",
    "prompt = \"Tell a short story about a friendly dragon.\"\n",
    "print(get_gemini_response(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Hugging Face Models\n",
    "\n",
    "* **Platform:** Hugging Face is a large platform and community that provides thousands of open-source AI models, including many LLMs. \n",
    "* **Characteristics:** Allows researchers and developers to access, share, and use pre-trained models. Notable for its `transformers` and `diffusers` libraries.\n",
    "* **Notable Models:** Llama (Meta), Falcon (TII), Mistral (Mistral AI), etc.\n",
    "* **Usage Example (Python with `transformers` library):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install transformers library if not already installed: pip install transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "def get_hf_response(prompt_text, model_name=\"distilgpt2\"):\n",
    "    try:\n",
    "        # Use pipeline to simplify model loading and usage\n",
    "        # distilgpt2 is a small, fast model for illustration\n",
    "        generator = pipeline('text-generation', model=model_name)\n",
    "        response = generator(prompt_text, max_new_tokens=50, num_return_sequences=1)\n",
    "        return response[0]['generated_text']\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "# Usage example\n",
    "prompt = \"One day, in a magical forest,\"\n",
    "print(get_hf_response(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Practical Applications of LLMs in Various Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLMs are being widely applied across many industries, bringing significant improvements:\n",
    "\n",
    "* **Virtual Assistants and Chatbots:**\n",
    "    * Providing 24/7 customer service, answering questions, technical support.\n",
    "    * Examples: ChatGPT, Bard, Copilot.\n",
    "* **Content Creation and Marketing:**\n",
    "    * Writing blog posts, marketing emails, product descriptions, ad scripts.\n",
    "    * Automating content generation for campaigns.\n",
    "* **Software Development:**\n",
    "    * Assisting programmers in writing code (code completion, code generation).\n",
    "    * Debugging, generating code documentation, converting programming languages.\n",
    "    * Example: GitHub Copilot.\n",
    "* **Education:**\n",
    "    * Creating personalized learning materials, summarizing lectures.\n",
    "    * Assisting students with homework, answering questions.\n",
    "* **Healthcare and Science:**\n",
    "    * Summarizing medical research, assisting with diagnosis (under expert supervision).\n",
    "    * Drug discovery, genomic data analysis.\n",
    "* **Finance:**\n",
    "    * Analyzing financial reports, summarizing market news.\n",
    "    * Assisting investment decisions (under human supervision).\n",
    "* **Legal:**\n",
    "    * Summarizing legal documents, assisting legal research.\n",
    "    * Drafting basic contracts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Summary\n",
    "\n",
    "This lesson provided an overview of Artificial Intelligence (AI) and Machine Learning (ML), clarifying their relationship. We explored **Generative AI**, an emerging field with the ability to create unique content, and its crucial role in the digital age. The core focus of the lesson was **Large Language Models (LLMs)**, their definition, characteristics, and foundational architecture, especially the **Transformer** and **Attention mechanism**. Finally, we explored popular LLM models like **OpenAI GPT**, **Google Gemini**, and models from **Hugging Face**, along with the diverse practical applications of LLMs in various fields. Understanding these concepts is a solid foundation to begin your journey with LangChain."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
