{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 10.1: Review and Advanced Prompt Engineering\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout the course, we've continuously interacted with Large Language Models (LLMs) through **prompts**. Prompt Engineering is not just an art but also a science, requiring a deep understanding of how LLMs process information. This lesson will help you review the basic principles and delve into advanced techniques to optimize prompts for specific tasks, using methods like \"role-playing\" and output formatting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Review of Basic Prompt Engineering Principles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt Engineering is the process of designing and refining inputs (prompts) for LLMs to achieve desired results. Here are the core principles we've learned:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Clarity and Specificity:**\n",
    "    * Avoid vague instructions. Be explicit about what you want.\n",
    "    * Use delimiters (e.g., `---`, `###`, `\"\"\"`) to separate different parts of the prompt (instructions, context, examples).\n",
    "* **Provide Full Context:**\n",
    "    * LLMs don't have your real-world knowledge. Provide all relevant information the LLM needs to perform the task.\n",
    "    * For tasks like Q&A or summarization, provide the source text.\n",
    "* **Request Output Format:**\n",
    "    * If you want structured output (e.g., JSON, lists, tables), specify it clearly.\n",
    "* **Use Examples (Few-shot prompting):**\n",
    "    * For complex tasks or specific formats, providing a few examples of (input, desired output) pairs can significantly improve performance.\n",
    "* **Iterative Prompt Development:**\n",
    "    * Prompt Engineering is an iterative process. Start with a simple prompt, test, analyze results, and refine.\n",
    "* **Avoid Bias and Harmful Content:**\n",
    "    * Be careful with the language you use in prompts to avoid generating biased or harmful responses.\n",
    "\n",
    "![Person refining a prompt on a screen](https://placehold.co/600x400/aabbcc/ffffff?text=Prompt+Refinement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Optimizing Prompts for Specific Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each task has its own requirements, and prompts need to be optimized accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Summarization:**\n",
    "    * **Goal:** Condense text into key points.\n",
    "    * **Techniques:**\n",
    "        * Specify desired length (e.g., \"summarize in 3 sentences,\" \"summarize under 50 words\").\n",
    "        * Specify style (e.g., \"summarize for a child,\" \"professional summary\").\n",
    "        * Ask for key points or core ideas.\n",
    "        * Example: \"Summarize the following text into 3 key points: [Text]\"\n",
    "* **Classification:**\n",
    "    * **Goal:** Assign a label or category to an input.\n",
    "    * **Techniques:**\n",
    "        * Provide a list of possible labels/categories.\n",
    "        * Ask the LLM to respond only with one of those labels.\n",
    "        * Use examples if categories are complex or ambiguous.\n",
    "        * Example: \"Classify the following sentence into one of these categories: ['Customer Support', 'Sales', 'Technical']. Sentence: 'I want to ask about my bill.'\"\n",
    "* **Information Extraction:**\n",
    "    * **Goal:** Retrieve specific entities or data from text.\n",
    "    * **Techniques:**\n",
    "        * Clearly specify the entities to extract (e.g., name, address, date, amount).\n",
    "        * Request structured output format (e.g., JSON) for easy parsing.\n",
    "        * Provide examples of desired input and extracted output.\n",
    "        * Example: \"Extract the product name and price from the following text. Respond in JSON: [Text]\"\n",
    "* **Code Generation:**\n",
    "    * **Goal:** Generate programming code based on a description.\n",
    "    * **Techniques:**\n",
    "        * Provide a clear description of the desired functionality, programming language, and any constraints (e.g., use specific libraries, class structure).\n",
    "        * Request runnable code snippets, including imports.\n",
    "        * Ask for code explanations or usage examples.\n",
    "        * Example: \"Write a Python function to calculate the factorial of a number. Include docstrings and usage examples.\"\n",
    "\n",
    "![Person typing code, with a thought bubble showing a prompt](https://placehold.co/600x400/ccaaee/ffffff?text=Code+Generation+Prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. \"Role-playing\" and \"Persona\" Techniques in Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This technique involves assigning a specific role or personality to the LLM to shape its tone, style, and approach to the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Role-playing:**\n",
    "    * **Concept:** Ask the LLM to act as an expert or a specific character.\n",
    "    * **Purpose:** Direct the response style, specialized knowledge, and tone.\n",
    "    * **Examples:**\n",
    "        * \"You are a professional data scientist. Explain the concept of overfitting in an easy-to-understand way for beginners.\"\n",
    "        * \"You are a famous chef. Provide a recipe for traditional Vietnamese pho.\"\n",
    "* **Persona:**\n",
    "    * **Concept:** Provide the LLM with a detailed description of a personality, goals, and sometimes even a history or preferences so it can respond consistently and more \"human-like.\"\n",
    "    * **Purpose:** Build chatbots with distinct personalities, creating a richer interactive experience.\n",
    "    * **Examples:**\n",
    "        * \"You are 'FunnyBot', an assistant who always tries to make people laugh. Answer the following question humorously: 'What's the weather like today?'\"\n",
    "        * \"You are 'History Professor', a serious and deeply knowledgeable person about past events. Answer a question about World War II.\"\n",
    "\n",
    "**Benefits:**\n",
    "* **Improved Response Quality:** LLMs can generate responses that are more appropriate for the context and expectations.\n",
    "* **Increased Consistency:** Maintain a consistent tone and style throughout the conversation.\n",
    "* **Enhanced User Experience:** Create a more natural and engaging interaction.\n",
    "\n",
    "![Chatbot icon with different persona masks (e.g., doctor, chef, comedian)](https://placehold.co/600x400/eeccaa/ffffff?text=Persona+Prompting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using Output Formatting Instructions (JSON, Markdown) in Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructing the LLM to format its output in a specific structure is crucial when you want to programmatically process its responses in your application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **JSON (JavaScript Object Notation):**\n",
    "    * **Purpose:** Ideal for extracting structured data, creating data objects, or when you need to integrate LLM output into other systems.\n",
    "    * **Techniques:**\n",
    "        * Clearly state that you want the output in JSON.\n",
    "        * Provide a JSON schema or an example of the desired JSON structure.\n",
    "        * Example:\n",
    "            ```\n",
    "            \"Respond in JSON in the following format:\n",
    "            {\n",
    "                \\\"product_name\\\": \\\"\\\n",
    "                \\\"price\\\": 0,\n",
    "                \\\"unit\\\": \\\"\\\"\n",
    "            }\n",
    "            \"\n",
    "            ```\n",
    "            Or use `response_format` in supported LLM APIs.\n",
    "* **Markdown:**\n",
    "    * **Purpose:** Generate human-readable, well-structured responses for end-users (e.g., lists, headings, code blocks, tables).\n",
    "    * **Techniques:**\n",
    "        * Specify the exact Markdown elements you want to use (e.g., \"use level 2 headings,\" \"use bulleted lists,\" \"format code blocks with three backticks\").\n",
    "        * Example:\n",
    "            ```\n",
    "            \"Summarize the following text and format it using Markdown, using headings for each main section and bullet points for details.\"\n",
    "            ```\n",
    "* **Benefits:**\n",
    "    * **Easy Parsing:** Makes it easy for your code to read and process the LLM's output.\n",
    "    * **Improved Readability:** Output is clearer and better structured for end-users.\n",
    "    * **Reduced Errors:** Decreases the likelihood of the LLM generating inconsistent or hard-to-use output.\n",
    "\n",
    "![JSON code snippet and a Markdown text snippet](https://placehold.co/600x400/ccbbff/ffffff?text=JSON+and+Markdown+Output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Summary\n",
    "\n",
    "This lesson helped you **review the basic principles of Prompt Engineering** and delve into advanced techniques. You learned how to **optimize prompts for specific tasks** such as summarization, classification, information extraction, and code generation. We explored the power of **\"Role-playing\" and \"Persona\"** techniques to shape the LLM's behavior and tone. Finally, you grasped the importance of **using output formatting instructions** like JSON and Markdown to ensure structured and easily processable responses. Mastering these techniques will help you build more powerful, accurate, and reliable LLM applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
