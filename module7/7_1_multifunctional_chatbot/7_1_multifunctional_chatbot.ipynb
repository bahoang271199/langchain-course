{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 7.1: Building a Multi-functional Chatbot\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous Modules, we learned about the core components of LangChain such as LLMs, Prompts, Chains, Agents, Tools, and Memory. Now it's time to combine all that knowledge to build a practical and useful application: a **multi-functional chatbot**. This chatbot will not only be able to chat but also perform tasks like searching for information, performing calculations, and interacting with external APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lesson will focus on designing the architecture for such a chatbot, how to use an Agent to orchestrate functions, and how to integrate a simple user interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Designing the Architecture for a Multi-functional Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a chatbot capable of performing various types of tasks, we need a flexible architecture where the Large Language Model (LLM) acts as the \"brain\" and other components extend its capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **LLM (Large Language Model):** The core of the chatbot, responsible for understanding natural language, reasoning, and generating responses.\n",
    "* **Agent:** Acts as the intelligent \"orchestrator.\" Instead of just answering, the Agent decides whether it needs to use a specific tool to fulfill the user's request.\n",
    "* **Tools:** Specific functions that the Agent can call to interact with the external world or perform specialized tasks. For example:\n",
    "    * **Web Search:** To look up current information or factual data.\n",
    "    * **Calculation:** To solve arithmetic problems.\n",
    "    * **API Interaction:** To retrieve data from external services (weather, quotes, task management, etc.).\n",
    "    * **Knowledge Base Query (RAG):** To answer questions based on internal documents.\n",
    "* **Memory:** Helps the chatbot maintain conversation context across multiple turns, allowing for more natural and seamless interactions.\n",
    "* **User Interface (UI):** Provides a way for users to interact with the chatbot (e.g., web interface, mobile application).\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using an Agent with Multiple Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key to creating a multi-functional chatbot is to equip the Agent with a diverse set of Tools and provide it with the ability to select the appropriate Tool based on the user's intent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Clear Tool Definitions:** Each Tool needs a unique `name` and a clear `description` outlining its function and the type of input it expects. The LLM will use this `description` to decide when to call the Tool.\n",
    "* **Tool Collection:** Place all Tools that the Agent can use into a list.\n",
    "* **Agent Prompt:** The Agent's prompt needs to instruct the LLM on how to think (Thought), act (Action), and observe (Observation) to use the Tools effectively. It also needs a placeholder for `agent_scratchpad` to track the Agent's intermediate steps.\n",
    "* **Memory Integration:** For the Agent to remember previous conversation turns, we will use a type of Memory (e.g., `ConversationBufferMemory`) and integrate it into the Agent's prompt via `MessagesPlaceholder`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Integrating a Simple User Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For users to interact with the chatbot, we need an interface. For Python applications, **Streamlit** and **Gradio** are two excellent frameworks for building web interfaces quickly and easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Streamlit:**\n",
    "    * **Pros:** Pure Python syntax, very fast for developing interactive data and ML applications. Supports various UI widgets, flexible layouts.\n",
    "    * **When to use:** Building dashboards, demo applications, or internal tools.\n",
    "* **Gradio:**\n",
    "    * **Pros:** Extremely simple to create interfaces for ML models and Python functions. Just a few lines of code can produce an interface.\n",
    "    * **When to use:** Quickly sharing models, creating simple demos.\n",
    "\n",
    "In this practical example, we will use **Streamlit** to build our chatbot's interface, as it offers better flexibility for a full-fledged chatbot application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Practical Example: Building and Running a Multi-functional Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a Streamlit chatbot with the following functionalities:\n",
    "* **Web Search:** Using `SerpAPIWrapper`.\n",
    "* **Calculation:** Using the `Calculator` Tool.\n",
    "* **Weather Lookup:** Using a simple Custom Tool (as built in previous lessons).\n",
    "* **Context Preservation:** Using `ConversationBufferMemory`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project Structure:**\n",
    "You will create a single Python file, for example `app.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparation:**\n",
    "* Ensure you have the necessary libraries installed: `langchain-openai`, `google-search-results`, `numexpr`, `streamlit`, `requests`.\n",
    "* Set the `OPENAI_API_KEY` and `SERPAPI_API_KEY` environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from langchain_community.tools import Tool\n",
    "from langchain_community.tools.calculator.tool import Calculator\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import requests\n",
    "import json # To handle JSON from weather API (if any)\n",
    "\n",
    "# Thi·∫øt l·∫≠p bi·∫øn m√¥i tr∆∞·ªùng cho kh√≥a API c·ªßa OpenAI v√† SerpAPI\n",
    "# ƒê·∫£m b·∫£o b·∫°n ƒë√£ ƒë·∫∑t c√°c bi·∫øn n√†y trong m√¥i tr∆∞·ªùng c·ªßa m√¨nh ho·∫∑c trong Streamlit Secrets\n",
    "# os.environ[\"OPENAI_API_KEY\"] = st.secrets[\"OPENAI_API_KEY\"]\n",
    "# os.environ[\"SERPAPI_API_KEY\"] = st.secrets[\"SERPAPI_API_KEY\"]\n",
    "\n",
    "# --- 1. Kh·ªüi t·∫°o LLM ---\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# --- 2. ƒê·ªãnh nghƒ©a c√°c Tools ---\n",
    "\n",
    "# C√¥ng c·ª• t√¨m ki·∫øm web\n",
    "search_tool = Tool(\n",
    "    name=\"Google Search\",\n",
    "    func=SerpAPIWrapper().run,\n",
    "    description=\"H·ªØu √≠ch khi b·∫°n c·∫ßn t√¨m ki·∫øm th√¥ng tin tr√™n Google v·ªÅ c√°c s·ª± ki·ªán hi·ªán t·∫°i ho·∫∑c d·ªØ li·ªáu th·ª±c t·∫ø.\" # Useful when you need to search for information on Google about current events or factual data.\n",
    ")\n",
    "\n",
    "# C√¥ng c·ª• t√≠nh to√°n\n",
    "calculator_tool = Calculator()\n",
    "\n",
    "# Custom Tool: Tra c·ª©u th·ªùi ti·∫øt gi·∫£ l·∫≠p (c√≥ th·ªÉ thay b·∫±ng API th·∫≠t n·∫øu c√≥)\n",
    "@st.cache_data(ttl=3600) # Cache k·∫øt qu·∫£ c·ªßa tool n√†y trong 1 gi·ªù\n",
    "def get_weather_data(location: str) -> str:\n",
    "    \"\"\"\n",
    "    L·∫•y th√¥ng tin th·ªùi ti·∫øt hi·ªán t·∫°i cho m·ªôt ƒë·ªãa ƒëi·ªÉm c·ª• th·ªÉ.\n",
    "    ƒê·∫ßu v√†o l√† t√™n th√†nh ph·ªë ho·∫∑c ƒë·ªãa ƒëi·ªÉm (v√≠ d·ª•: \"H√† N·ªôi\", \"ƒê√† N·∫µng\", \"Tokyo\").\n",
    "    Tr·∫£ v·ªÅ chu·ªói m√¥ t·∫£ th·ªùi ti·∫øt.\n",
    "    \"\"\"\n",
    "    location_lower = location.lower()\n",
    "    if \"h√† n·ªôi\" in location_lower: # Hanoi\n",
    "        return \"Th·ªùi ti·∫øt H√† N·ªôi: 28¬∞C, tr·ªùi n·∫Øng, ƒë·ªô ·∫©m 70%, gi√≥ nh·∫π.\" # Hanoi Weather: 28¬∞C, sunny, 70% humidity, light wind.\n",
    "    elif \"ƒë√† n·∫µng\" in location_lower: # Da Nang\n",
    "        return \"Th·ªùi ti·∫øt ƒê√† N·∫µng: 30¬∞C, tr·ªùi quang ƒë√£ng, ƒë·ªô ·∫©m 65%, kh√¥ng c√≥ m∆∞a.\" # Da Nang Weather: 30¬∞C, clear sky, 65% humidity, no rain.\n",
    "    elif \"london\" in location_lower:\n",
    "        return \"Th·ªùi ti·∫øt London: 15¬∞C, nhi·ªÅu m√¢y, c√≥ m∆∞a ph√πn, gi√≥ m·∫°nh.\" # London Weather: 15¬∞C, cloudy, light drizzle, strong wind.\n",
    "    elif \"tokyo\" in location_lower:\n",
    "        return \"Th·ªùi ti·∫øt Tokyo: 25¬∞C, n·∫Øng ƒë·∫πp, ƒë·ªô ·∫©m 60%.\" # Tokyo Weather: 25¬∞C, sunny, 60% humidity.\n",
    "    else:\n",
    "        return f\"Kh√¥ng t√¨m th·∫•y th√¥ng tin th·ªùi ti·∫øt cho ƒë·ªãa ƒëi·ªÉm: {location}.\" # Weather information not found for location:\n",
    "\n",
    "weather_tool = Tool(\n",
    "    name=\"Weather Lookup\",\n",
    "    func=get_weather_data,\n",
    "    description=\"H·ªØu √≠ch khi b·∫°n c·∫ßn bi·∫øt th√¥ng tin th·ªùi ti·∫øt hi·ªán t·∫°i c·ªßa m·ªôt th√†nh ph·ªë c·ª• th·ªÉ.\" # Useful when you need to know the current weather information for a specific city.\n",
    ")\n",
    "\n",
    "tools = [search_tool, calculator_tool, weather_tool]\n",
    "\n",
    "# --- 3. Thi·∫øt l·∫≠p Memory cho Agent ---\n",
    "# S·ª≠ d·ª•ng ConversationBufferMemory ƒë·ªÉ duy tr√¨ l·ªãch s·ª≠ tr√≤ chuy·ªán\n",
    "# memory_key ph·∫£i kh·ªõp v·ªõi variable_name trong MessagesPlaceholder c·ªßa prompt\n",
    "# return_messages=True ƒë·ªÉ l·ªãch s·ª≠ ƒë∆∞·ª£c tr·∫£ v·ªÅ d∆∞·ªõi d·∫°ng danh s√°ch c√°c ƒë·ªëi t∆∞·ª£ng Message\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# --- 4. ƒê·ªãnh nghƒ©a Prompt cho Agent ---\n",
    "# Prompt n√†y h∆∞·ªõng d·∫´n LLM c√°ch suy nghƒ© v√† s·ª≠ d·ª•ng c√°c c√¥ng c·ª•.\n",
    "# MessagesPlaceholder(variable_name=\"chat_history\") l√† n∆°i l·ªãch s·ª≠ tr√≤ chuy·ªán ƒë∆∞·ª£c ch√®n v√†o.\n",
    "# MessagesPlaceholder(variable_name=\"agent_scratchpad\") l√† n∆°i Agent ghi l·∫°i c√°c Thought, Action, Observation.\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"B·∫°n l√† m·ªôt tr·ª£ l√Ω ƒëa ch·ª©c nƒÉng h·ªØu √≠ch. B·∫°n c√≥ quy·ªÅn truy c·∫≠p v√†o c√°c c√¥ng c·ª• sau: {tools}. S·ª≠ d·ª•ng ch√∫ng ƒë·ªÉ tr·∫£ l·ªùi c√°c c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng. H√£y duy tr√¨ ng·ªØ c·∫£nh cu·ªôc tr√≤ chuy·ªán v√† tr·∫£ l·ªùi m·ªôt c√°ch t·ª± nhi√™n.\"), # You are a helpful multi-functional assistant. You have access to the following tools: {tools}. Use them to answer user questions. Maintain conversation context and respond naturally.\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "# --- 5. T·∫°o Agent v√† Agent Executor ---\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memory=memory, # Truy·ªÅn ƒë·ªëi t∆∞·ª£ng memory v√†o Agent Executor\n",
    "    verbose=True, # B·∫≠t verbose ƒë·ªÉ xem qu√° tr√¨nh suy nghƒ© c·ªßa Agent trong console\n",
    "    handle_parsing_errors=True # Cho ph√©p Agent c·ªë g·∫Øng t·ª± s·ª≠a l·ªói ph√¢n t√≠ch c√∫ ph√°p\n",
    ")\n",
    "\n",
    "# --- 6. Giao di·ªán ng∆∞·ªùi d√πng Streamlit ---\n",
    "st.set_page_config(page_title=\"Chatbot ƒêa Ch·ª©c NƒÉng\", page_icon=\"ü§ñ\") # Multi-functional Chatbot\n",
    "st.title(\"ü§ñ Chatbot ƒêa Ch·ª©c NƒÉng\") # Multi-functional Chatbot\n",
    "\n",
    "# Kh·ªüi t·∫°o l·ªãch s·ª≠ tr√≤ chuy·ªán trong session state n·∫øu ch∆∞a c√≥\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# Hi·ªÉn th·ªã l·ªãch s·ª≠ tr√≤ chuy·ªán\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "\n",
    "# X·ª≠ l√Ω ƒë·∫ßu v√†o c·ªßa ng∆∞·ªùi d√πng\n",
    "if user_query := st.chat_input(\"B·∫°n mu·ªën h·ªèi g√¨?\"): # What do you want to ask?\n",
    "    # Th√™m tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_query})\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(user_query)\n",
    "\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        with st.spinner(\"ƒêang suy nghƒ©...\"): # Thinking...\n",
    "            try:\n",
    "                # G·ªçi Agent Executor v·ªõi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng\n",
    "                # Agent Executor s·∫Ω t·ª± ƒë·ªông l·∫•y l·ªãch s·ª≠ t·ª´ 'memory' ƒë√£ ƒë∆∞·ª£c truy·ªÅn v√†o\n",
    "                response = agent_executor.invoke({\"input\": user_query})\n",
    "                ai_response = response[\"output\"]\n",
    "            except Exception as e:\n",
    "                ai_response = f\"Xin l·ªói, c√≥ l·ªói x·∫£y ra: {e}. Vui l√≤ng th·ª≠ l·∫°i ho·∫∑c h·ªèi c√¢u h·ªèi kh√°c.\" # Sorry, an error occurred: {e}. Please try again or ask another question.\n",
    "                st.error(ai_response)\n",
    "        \n",
    "        st.markdown(ai_response)\n",
    "        # Th√™m ph·∫£n h·ªìi c·ªßa AI v√†o l·ªãch s·ª≠\n",
    "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "\n",
    "# N√∫t ƒë·ªÉ x√≥a l·ªãch s·ª≠ tr√≤ chuy·ªán\n",
    "if st.button(\"X√≥a l·ªãch s·ª≠ tr√≤ chuy·ªán\"): # Clear chat history\n",
    "    st.session_state.messages = []\n",
    "    memory.clear() # X√≥a l·ªãch s·ª≠ trong LangChain memory\n",
    "    st.experimental_rerun() # Ch·∫°y l·∫°i ·ª©ng d·ª•ng ƒë·ªÉ c·∫≠p nh·∫≠t giao di·ªán\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
