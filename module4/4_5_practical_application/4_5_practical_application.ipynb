{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4.5: Practical Application - Building an API-Interacting Agent\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous lessons, we learned the theory behind **Agents** and how they use **Tools** to extend the capabilities of Large Language Models (LLMs). Now it's time to put that knowledge into practice by building an Agent capable of interacting with an external API. This practical exercise will guide you step-by-step through creating a **Custom Tool** and integrating it into an Agent to solve real-world tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objectives of this Practical Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main objectives of this practical exercise are to:\n",
    "* Reinforce knowledge about how to create and use **Custom Tools**.\n",
    "* Build an **Agent** capable of making decisions and using custom Tools to interact with a public API.\n",
    "* Gain a deeper understanding of the Agent's reasoning and action flow when working with Tools.\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Environment Setup and API Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, ensure you have installed the necessary libraries and set up your API key for your LLM model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Required Libraries:**\n",
    "```bash\n",
    "pip install langchain-openai openai requests pydantic\n",
    "```\n",
    "* `langchain-openai`: LangChain integration with OpenAI.\n",
    "* `openai`: Official OpenAI Python library.\n",
    "* `requests`: For making HTTP requests to external APIs.\n",
    "* `pydantic`: For defining input schemas for Tools (optional, but recommended)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**API Key Setup:**\n",
    "```python\n",
    "import os\n",
    "# Set your API key in an environment variable\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Public API Selection:**\n",
    "We will use the **Quotable API** (`https://api.quotable.io/random`) to fetch random quotes. This is a simple API that does not require authentication or API keys, making it ideal for illustration purposes.\n",
    "To add versatility, we will also reuse the mock weather lookup tool from the previous lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Writing Custom Tools to Interact with APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create two Custom Tools: one to fetch a random quote and one for mock weather lookup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Custom Tool: Get Random Quote (`get_random_quote`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Tool will call the Quotable API and return a random quote along with its author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_random_quote() -> str:\n",
    "    \"\"\"\n",
    "    Lấy một câu danh ngôn ngẫu nhiên từ Quotable API.\n",
    "    Không cần đầu vào.\n",
    "    Trả về một chuỗi chứa câu danh ngôn và tác giả.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(\"https://api.quotable.io/random\")\n",
    "        response.raise_for_status() # Ném lỗi cho các mã trạng thái HTTP xấu (4xx hoặc 5xx)\n",
    "        data = response.json()\n",
    "        content = data.get(\"content\", \"Không có nội dung câu danh ngôn.\")\n",
    "        author = data.get(\"author\", \"Không rõ tác giả.\")\n",
    "        return f\"Câu danh ngôn: '{content}' - Tác giả: {author}\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Lỗi khi lấy câu danh ngôn: {e}\"\n",
    "\n",
    "# Kiểm tra Tool tùy chỉnh\n",
    "print(\"--- Kiểm tra Custom Quote Tool ---\")\n",
    "print(get_random_quote())\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Custom Tool: Mock Weather Lookup (`get_weather_data`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Tool similar to the one in Lesson 4.4, used to illustrate that an Agent can use multiple types of Tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather_data(location: str) -> str:\n",
    "    \"\"\"\n",
    "    Lấy thông tin thời tiết hiện tại cho một địa điểm cụ thể.\n",
    "    Đầu vào là tên thành phố hoặc địa điểm (ví dụ: \"Hà Nội\", \"Đà Nẵng\", \"Tokyo\").\n",
    "    Trả về chuỗi mô tả thời tiết.\n",
    "    \"\"\"\n",
    "    location_lower = location.lower()\n",
    "    if \"hanoi\" in location_lower:\n",
    "        return \"Thời tiết Hà Nội: 28°C, trời nắng, độ ẩm 70%, gió nhẹ.\"\n",
    "    elif \"da nang\" in location_lower:\n",
    "        return \"Thời tiết Đà Nẵng: 30°C, trời quang đãng, độ ẩm 65%, không có mưa.\"\n",
    "    elif \"london\" in location_lower:\n",
    "        return \"Thời tiết London: 15°C, nhiều mây, có mưa phùn, gió mạnh.\"\n",
    "    elif \"tokyo\" in location_lower:\n",
    "        return \"Thời tiết Tokyo: 25°C, nắng đẹp, độ ẩm 60%.\"\n",
    "    else:\n",
    "        return f\"Không tìm thấy thông tin thời tiết cho địa điểm: {location}.\"\n",
    "\n",
    "# Kiểm tra Tool tùy chỉnh\n",
    "print(\"--- Kiểm tra Custom Weather Tool ---\")\n",
    "print(get_weather_data(\"Hanoi\"))\n",
    "print(get_weather_data(\"Sydney\"))\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building an Agent Using Custom Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will combine the LLM with these Custom Tools to create an Agent capable of making decisions and using them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain.tools import Tool\n",
    "\n",
    "# Thiết lập biến môi trường cho khóa API của OpenAI\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "# 1. Khởi tạo LLM\n",
    "# Sử dụng temperature thấp để Agent ra quyết định ổn định hơn\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# 2. Tập hợp danh sách các Tools mà Agent có thể sử dụng\n",
    "tools = [\n",
    "    get_random_quote, # Tool lấy câu danh ngôn\n",
    "    get_weather_data  # Tool tra cứu thời tiết\n",
    "]\n",
    "\n",
    "# 3. Định nghĩa Prompt cho Agent\n",
    "# Prompt này sẽ hướng dẫn LLM cách suy nghĩ và sử dụng các công cụ.\n",
    "# MessagesPlaceholder(variable_name=\"agent_scratchpad\") là rất quan trọng\n",
    "# để Agent ghi lại các Thought, Action, Observation của mình.\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Bạn là một trợ lý hữu ích. Bạn có quyền truy cập vào các công cụ sau: {tools}. Sử dụng chúng để trả lời các câu hỏi. Nếu câu hỏi không liên quan đến thời tiết hoặc danh ngôn, hãy trả lời bằng kiến thức chung của bạn.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"), # Để duy trì lịch sử trò chuyện\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "# 4. Tạo Agent\n",
    "# create_react_agent tạo một Zero-shot ReAct Agent\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "# 5. Tạo Agent Executor\n",
    "# Cấu hình max_iterations để ngăn vòng lặp vô hạn\n",
    "# Cấu hình handle_parsing_errors để Agent có thể tự sửa lỗi\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True, # Để xem quá trình suy nghĩ của Agent\n",
    "    max_iterations=5, # Giới hạn số bước để tránh vòng lặp vô hạn\n",
    "    handle_parsing_errors=True # Cho phép Agent cố gắng tự sửa lỗi phân tích cú pháp\n",
    ")\n",
    "\n",
    "print(\"\\nĐã xây dựng Agent với Custom Tools.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Executing and Testing the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try asking a few questions to your Agent to see how it interacts with the APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Thực thi Agent ---\n",
    "print(\"\\n--- Bắt đầu kiểm tra Agent tương tác API ---\") # Starting API-interacting Agent test\n",
    "chat_history = []\n",
    "\n",
    "# Câu hỏi 1: Yêu cầu lấy câu danh ngôn ngẫu nhiên\n",
    "query_1 = \"Hãy cho tôi một câu danh ngôn ngẫu nhiên.\"\n",
    "print(f\"\\nNgười dùng: {query_1}\") # User:\n",
    "response_1 = agent_executor.invoke({\"input\": query_1, \"chat_history\": chat_history})\n",
    "chat_history.extend([HumanMessage(content=query_1), AIMessage(content=response_1[\"output\"])])\n",
    "print(f\"Agent: {response_1['output']}\")\n",
    "\n",
    "# Câu hỏi 2: Yêu cầu tra cứu thời tiết\n",
    "query_2 = \"Thời tiết ở Tokyo hôm nay thế nào?\"\n",
    "print(f\"\\nNgười dùng: {query_2}\") # User:\n",
    "response_2 = agent_executor.invoke({\"input\": query_2, \"chat_history\": chat_history})\n",
    "chat_history.extend([HumanMessage(content=query_2), AIMessage(content=response_2[\"output\"])])\n",
    "print(f\"Agent: {response_2['output']}\")\n",
    "\n",
    "# Câu hỏi 3: Câu hỏi không liên quan đến Tools, LLM sẽ trả lời bằng kiến thức chung\n",
    "query_3 = \"Thủ đô của Canada là gì?\"\n",
    "print(f\"\\nNgười dùng: {query_3}\") # User:\n",
    "response_3 = agent_executor.invoke({\"input\": query_3, \"chat_history\": chat_history})\n",
    "chat_history.extend([HumanMessage(content=query_3), AIMessage(content=response_3[\"output\"])])\n",
    "print(f\"Agent: {response_3['output']}\")\n",
    "\n",
    "# Câu hỏi 4: Yêu cầu lấy câu danh ngôn một lần nữa\n",
    "query_4 = \"Cho tôi một câu danh ngôn khác.\"\n",
    "print(f\"\\nNgười dùng: {query_4}\") # User:\n",
    "response_4 = agent_executor.invoke({\"input\": query_4, \"chat_history\": chat_history})\n",
    "chat_history.extend([HumanMessage(content=query_4), AIMessage(content=response_4[\"output\"])])\n",
    "print(f\"Agent: {response_4['output']}\")\n",
    "\n",
    "print(\"\\n--- Kết thúc kiểm tra Agent tương tác API ---\") # Ending API-interacting Agent test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "* When you ask for a quote, the Agent will recognize that the `get_random_quote` Tool is appropriate and invoke it.\n",
    "* When you ask about the weather, the Agent will invoke the `get_weather_data` Tool.\n",
    "* For questions unrelated to the Tools' functionality (e.g., \"What is the capital of Canada?\"), the Agent will not find a suitable Tool and will attempt to answer using the LLM's internal knowledge.\n",
    "* Using `verbose=True` in `AgentExecutor` will help you observe the Agent's detailed thought process (`Thought`), actions (`Action`), and observations (`Observation`), giving you a clearer understanding of how it makes decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Summary\n",
    "\n",
    "In this lesson, you practiced building an **Agent** capable of interacting with **external APIs** through **Custom Tools**. You learned how to:\n",
    "* Select a public API and design a **Custom Tool** to call it (e.g., `get_random_quote` for the Quotable API).\n",
    "* Reuse and integrate other Custom Tools (e.g., `get_weather_data`).\n",
    "* **Build an Agent** by connecting an LLM with a list of Tools and a carefully designed Prompt.\n",
    "* **Execute the Agent** and observe how it autonomously selects and uses the appropriate Tools to answer API-related questions.\n",
    "\n",
    "This practical exercise has reinforced your knowledge of Agents and Tools, allowing you to extend the capabilities of LLM applications to interact with the external world in a flexible and intelligent manner."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
