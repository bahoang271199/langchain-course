{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4.4: Custom Agents and Agent Executor\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous lesson, we explored common Agent types like Zero-shot ReAct Agent and Conversational Agent. While these built-in Agents are powerful, sometimes you need an Agent with unique reasoning logic or behavior that doesn't fit the available patterns. This lesson will guide you on how to build **Custom Agents** and how to control their behavior through the **Agent Executor**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Building Agents with Custom Logic (Custom Agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. When are Custom Agents Needed?\n",
    "\n",
    "You should consider building a Custom Agent when:\n",
    "\n",
    "* **Complex Reasoning Logic:** Built-in Agent strategies (like ReAct) might not be sufficient for very complex or non-standard reasoning scenarios. You want precise control over how the LLM generates \"Thought\" and \"Action.\"\n",
    "\n",
    "* **Specific Response Format:** You need the Agent to produce actions or responses in a particular format not supported by default Agents.\n",
    "\n",
    "* **Deep Integration with Your System:** You want the Agent to have a specific way of interacting with other components in your architecture that isn't just a standalone \"Tool.\"\n",
    "\n",
    "* **Performance Optimization:** You want to fine-tune the reasoning-action loop to achieve better performance for your specific use case.\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Approaches to Building Custom Agents\n",
    "\n",
    "Building a Custom Agent typically involves redefining how the LLM reasons and formats its output so that the Agent Executor can understand and execute it. This is often done by customizing the Prompt and potentially the Output Parser.\n",
    "\n",
    "* **Prompt Customization:** This is the most common approach. You will create a very detailed `ChatPromptTemplate` that instructs the LLM on how to think, when to use a tool, and how to format its actions.\n",
    "\n",
    "* **Output Parser Customization:** If your LLM outputs actions in a non-standard format, you will need a custom `OutputParser` to parse the LLM's output into `AgentAction` or `AgentFinish` objects that the Agent Executor can understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Controlling Agent Behavior via AgentExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Agent Executor** is the component responsible for orchestrating the Agent's reasoning-action loop. It provides several important parameters that allow you to control the Agent's behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Key Parameters of `AgentExecutor`\n",
    "\n",
    "* **`agent`**: The Agent object that the Executor will run (e.g., an Agent created by `create_react_agent`).\n",
    "* **`tools`**: The list of tools that the Agent can use.\n",
    "* **`verbose`**: (Boolean, default `False`) If `True`, the Agent Executor will print out the Agent's thoughts, actions, and observations, which is very useful for debugging and understanding the flow.\n",
    "* **`handle_parsing_errors`**: (Boolean or string, default `False`) Controls how parsing errors in the LLM's output are handled. If `True`, errors will be passed back to the LLM for it to attempt self-correction.\n",
    "* **`max_iterations`**: (Integer, default `15`) The maximum number of iterations the Agent Executor will perform before stopping. This helps prevent infinite loops.\n",
    "* **`max_execution_time`**: (Float) The maximum time (in seconds) the Agent Executor will run before stopping.\n",
    "* **`return_intermediate_steps`**: (Boolean, default `False`) If `True`, the `invoke` output will include a list of the intermediate steps (Thought, Action, Observation) the Agent took.\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Handling Errors and Infinite Loops in Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agents, due to their dynamic nature, can encounter issues such as parsing errors or infinite loops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Handling Parsing Errors\n",
    "\n",
    "The LLM can sometimes generate output that doesn't conform to the format expected by the Agent Executor (e.g., incorrect syntax for tool calls).\n",
    "\n",
    "* **Causes:** Prompt is not clear enough, LLM hallucination, or LLM `temperature` is too high.\n",
    "* **Solutions:**\n",
    "    * **Improve Prompt:** Make the prompt clearer, provide examples of the desired action format.\n",
    "    * **`handle_parsing_errors=True`:** Allows the Agent Executor to pass the parsing error back to the LLM as an Observation. The LLM can then attempt to self-correct in the next turn.\n",
    "    * **Lower `temperature`:** Helps the LLM generate more consistent output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Handling Infinite Loops\n",
    "\n",
    "An Agent can fall into an infinite loop if it continuously takes ineffective actions or fails to achieve its goal.\n",
    "\n",
    "* **Causes:**\n",
    "    * The LLM cannot reason correctly to break out of a situation.\n",
    "    * Tools return unhelpful or misleading results.\n",
    "    * Lack of appropriate information or tools to solve the problem.\n",
    "* **Solutions:**\n",
    "    * **`max_iterations` and `max_execution_time`:** These are the most important safety measures. They ensure the Agent will stop after a certain number of steps or time, preventing wasted resources.\n",
    "    * **Improve Prompt:** Instruct the LLM on how to recognize when to stop or when to state that it cannot solve the problem.\n",
    "    * **Improve Tools:** Ensure tools return clear and useful Observations.\n",
    "    * **Add an \"escape hatch\" tool:** For example, a tool named `give_up` that the Agent can call when it cannot find a solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Practical Example: Building an Agent Capable of Interacting with an External API (Weather API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a simple Agent capable of looking up weather information by interacting with a mock weather API via a Custom Tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparation:**\n",
    "* Ensure you have `langchain-openai` installed.\n",
    "* Set the `OPENAI_API_KEY` environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries if not already installed\n",
    "# pip install langchain-openai openai pydantic\n",
    "\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain.tools import BaseTool, tool\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Type\n",
    "\n",
    "# Set environment variable for OpenAI API key\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "# 1. Initialize LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# 2. Create a Custom Tool to interact with a mock weather API\n",
    "# We will use the @tool decorator for simplicity\n",
    "\n",
    "@tool\n",
    "def get_weather_data(location: str) -> str:\n",
    "    \"\"\"\n",
    "    Get current weather information for a specific location.\n",
    "    Input is the city or location name (e.g., \"Hanoi\", \"Da Nang\", \"Tokyo\").\n",
    "    Returns a string describing the weather.\n",
    "    \"\"\"\n",
    "    location_lower = location.lower()\n",
    "    if \"hanoi\" in location_lower:\n",
    "        return \"Hanoi Weather: 28째C, sunny, 70% humidity, light wind.\"\n",
    "    elif \"da nang\" in location_lower:\n",
    "        return \"Da Nang Weather: 30째C, clear sky, 65% humidity, no rain.\"\n",
    "    elif \"london\" in location_lower:\n",
    "        return \"London Weather: 15째C, cloudy, light drizzle, strong wind.\"\n",
    "    elif \"tokyo\" in location_lower:\n",
    "        return \"Tokyo Weather: 25째C, sunny, 60% humidity.\"\n",
    "    else:\n",
    "        return f\"Weather information not found for location: {location}.\"\n",
    "\n",
    "# Gather all Tools the Agent can use\n",
    "tools = [get_weather_data]\n",
    "\n",
    "# 3. Define Prompt for the Agent\n",
    "# This prompt will instruct the LLM on how to think and use the get_weather_data tool.\n",
    "# MessagesPlaceholder(variable_name=\"agent_scratchpad\") is crucial for the Agent to record its Thoughts, Actions, and Observations.\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful weather assistant. You have access to the 'get_weather_data' tool to look up weather. Use it to answer weather-related questions.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "# 4. Create Agent\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "# 5. Create Agent Executor\n",
    "# Configure max_iterations to prevent infinite loops\n",
    "# Configure handle_parsing_errors so the Agent can attempt self-correction\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True, # To see the thought process\n",
    "    max_iterations=5, # Limit the number of steps to prevent infinite loops\n",
    "    handle_parsing_errors=True # Allow the Agent to attempt self-correction for parsing errors\n",
    ")\n",
    "\n",
    "# --- Execute the Agent ---\n",
    "print(\"--- Starting Agent Executor with Custom Weather Tool ---\")\n",
    "chat_history = []\n",
    "\n",
    "# Question 1: Requires weather lookup\n",
    "query_1 = \"What's the weather like today in Da Nang?\"\n",
    "print(f\"\\nUser: {query_1}\")\n",
    "response_1 = agent_executor.invoke({\"input\": query_1, \"chat_history\": chat_history})\n",
    "chat_history.extend([HumanMessage(content=query_1), AIMessage(content=response_1[\"output\"])])\n",
    "print(f\"Agent: {response_1['output']}\")\n",
    "\n",
    "# Question 2: Requires weather lookup for a location with no data\n",
    "query_2 = \"What's the weather like in Sydney right now?\"\n",
    "print(f\"\\nUser: {query_2}\")\n",
    "response_2 = agent_executor.invoke({\"input\": query_2, \"chat_history\": chat_history})\n",
    "chat_history.extend([HumanMessage(content=query_2), AIMessage(content=response_2[\"output\"])])\n",
    "print(f\"Agent: {response_2['output']}\")\n",
    "\n",
    "# Question 3: Question outside the Agent's capability (no suitable tool)\n",
    "query_3 = \"Calculate the sum of 123 and 456.\"\n",
    "print(f\"\\nUser: {query_3}\")\n",
    "response_3 = agent_executor.invoke({\"input\": query_3, \"chat_history\": chat_history})\n",
    "chat_history.extend([HumanMessage(content=query_3), AIMessage(content=response_3[\"output\"])])\n",
    "print(f\"Agent: {response_3['output']}\")\n",
    "\n",
    "print(\"--- Agent Executor Ended ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "* We created a simple Python function `get_weather_data` and turned it into a Tool using the `@tool` decorator. This Tool simulates calling a weather API.\n",
    "* The `AgentExecutor` is configured with `max_iterations=5` to limit the number of steps the Agent can take, and `handle_parsing_errors=True` so it can attempt to self-correct if the LLM produces malformed output.\n",
    "* When you ask a weather-related question, the Agent will use the `get_weather_data` Tool to look up and answer. If the location is not in the mock data, the Tool will return an error message, and the Agent will relay that message.\n",
    "* For the calculation question, since the Agent does not have a `Calculator` tool (only `get_weather_data`), it will attempt to answer using the LLM's own knowledge or state that it cannot perform the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Summary\n",
    "\n",
    "This lesson provided in-depth knowledge about **Custom Agents** and how to control them through the **Agent Executor**. You understood when to build an Agent with custom logic and how `AgentExecutor` parameters like `max_iterations` and `handle_parsing_errors` help manage Agent behavior. We also discussed how to **handle parsing errors** and **prevent infinite loops**. Finally, you practiced **building an Agent capable of interacting with an external API** (a mock weather API) by creating a Custom Tool and integrating it into the Agent Executor. Mastering these techniques is key to designing and deploying powerful, reliable, and problem-solving Agents in the real world."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
