{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4.2: Tools in LangChain\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Lesson 4.1, we introduced **Agents** and how they use Large Language Models (LLMs) for decision-making and planning. An indispensable part of an Agent's capabilities is the use of **Tools**. Tools allow Agents to interact with the external world and perform specific tasks beyond the pure text generation capabilities of an LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Concept of Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. What are Tools?\n",
    "\n",
    "**Tools** in LangChain are functions or APIs that an Agent can invoke to perform specific actions. They serve as the interface for the Agent to interact with external systems, gather information, or perform calculations.\n",
    "\n",
    "* **Relationship:** If the LLM is the \"brain\" of the Agent, then Tools are its \"hands and feet.\" The LLM thinks about the problem and decides what needs to be done, then it selects an appropriate Tool to perform that action.\n",
    "\n",
    "* **Important Description:** Each Tool has a clear textual description of its functionality. The LLM will read this description to understand what the Tool does and when to use it.\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Why are Tools Needed?\n",
    "\n",
    "* **Extend LLM Capabilities:** LLMs have vast knowledge but cannot perform tasks like real-time searching, complex calculations, reading files, or making API calls. Tools fill this gap.\n",
    "\n",
    "* **Up-to-date Information:** LLMs have static knowledge up to their training cutoff. Tools (e.g., web search) allow the Agent to access the latest information.\n",
    "\n",
    "* **Perform Actions:** Enable the Agent to interact with other systems (e.g., sending emails, updating databases).\n",
    "\n",
    "* **Reduce Hallucinations:** By using Tools to fetch factual information, the Agent can provide more accurate and less fabricated answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Custom Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create custom tools for your Agent to perform any function you define. LangChain provides two main ways to do this: using the `tool` decorator or inheriting from `BaseTool`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Using the `tool` decorator (Simplest Way)\n",
    "\n",
    "The simplest way to create a Tool is to use the `@tool` decorator from `langchain.tools`. It will automatically turn a Python function into a Tool.\n",
    "\n",
    "* **Characteristics:**\n",
    "    * The function must have a clear docstring describing its functionality. This docstring will be used by the LLM to decide when to call the Tool.\n",
    "    * The function takes a single argument (usually a string) as the Tool's input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the library if not already installed\n",
    "# pip install langchain\n",
    "\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_current_weather(location: str) -> str:\n",
    "    \"\"\"\n",
    "    Get the current weather information for a specific location.\n",
    "    Input is the city or location name.\n",
    "    Example: \"Hanoi\", \"London\", \"New York\".\n",
    "    \"\"\"\n",
    "    if \"Hanoi\" in location:\n",
    "        return \"Hanoi Weather: 28째C, sunny, 70% humidity.\"\n",
    "    elif \"London\" in location:\n",
    "        return \"London Weather: 15째C, cloudy, light rain.\"\n",
    "    else:\n",
    "        return \"Weather information not found for this location.\"\n",
    "\n",
    "# You can test the Tool like a regular function\n",
    "print(get_current_weather(\"Hanoi\"))\n",
    "print(get_current_weather(\"Da Nang\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Inheriting from `BaseTool` (More Granular Control)\n",
    "\n",
    "If you need more granular control over the Tool (e.g., input validation with Pydantic, complex error handling), you can inherit from the `BaseTool` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the library if not already installed\n",
    "# pip install langchain pydantic\n",
    "\n",
    "from langchain.tools import BaseTool\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Type\n",
    "\n",
    "class WeatherToolInput(BaseModel):\n",
    "    \"\"\"Input for WeatherTool.\"\"\"\n",
    "    location: str = Field(description=\"City or location name to get weather information.\")\n",
    "\n",
    "class CustomWeatherTool(BaseTool):\n",
    "    name = \"get_weather_information\"\n",
    "    description = \"Useful when you need to get the current weather information for a specific location.\"\n",
    "    args_schema: Type[BaseModel] = WeatherToolInput # Define input schema\n",
    "\n",
    "    def _run(self, location: str) -> str:\n",
    "        \"\"\"Use the tool synchronously.\"\"\"\n",
    "        if \"Hanoi\" in location:\n",
    "            return \"Hanoi Weather: 28째C, sunny, 70% humidity.\"\n",
    "        elif \"London\" in location:\n",
    "            return \"London Weather: 15째C, cloudy, light rain.\"\n",
    "        else:\n",
    "            return \"Weather information not found for this location.\"\n",
    "\n",
    "    async def _arun(self, location: str) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        # In this simple example, we just call the synchronous _run\n",
    "        return self._run(location)\n",
    "\n",
    "# Initialize the Tool\n",
    "custom_weather_tool = CustomWeatherTool()\n",
    "\n",
    "# You can test the Tool\n",
    "print(custom_weather_tool.run(\"Hanoi\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using LangChain's Built-in Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain provides a large collection of built-in tools for many common tasks. Here are some examples:\n",
    "\n",
    "**Preparation:**\n",
    "* Ensure you have `langchain-openai` and the necessary dependencies for each Tool installed.\n",
    "* Set the `OPENAI_API_KEY` environment variable.\n",
    "* For `SerpAPIWrapper`, you'll need a `SERPAPI_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Set environment variables for OpenAI and SerpAPI keys\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n",
    "# os.environ[\"SERPAPI_API_KEY\"] = \"YOUR_SERPAPI_API_KEY\" # Required for SerpAPIWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. `SerpAPIWrapper` (Web Search)\n",
    "\n",
    "* **Concept:** Allows the Agent to perform web searches using SerpAPI (a paid API that provides search results from Google and other search engines).\n",
    "* **When to Use:** When the Agent needs up-to-date information, factual data, or answers to questions not present in its training data.\n",
    "* **Requirement:** `pip install google-search-results` and `SERPAPI_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if not already installed:\n",
    "# pip install google-search-results langchain\n",
    "\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from langchain.tools import Tool\n",
    "\n",
    "# Initialize SerpAPIWrapper\n",
    "serpapi_wrapper = SerpAPIWrapper()\n",
    "\n",
    "# Create Tool from SerpAPIWrapper\n",
    "search_tool = Tool(\n",
    "    name=\"Google Search\",\n",
    "    func=serpapi_wrapper.run,\n",
    "    description=\"Useful when you need to search for information on Google about current events or factual data.\"\n",
    ")\n",
    "\n",
    "# Example of using the Tool directly (not through an Agent)\n",
    "# print(search_tool.run(\"Weather in Da Nang today\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. `Calculator`\n",
    "\n",
    "* **Concept:** A simple Tool to perform basic mathematical calculations.\n",
    "* **When to Use:** When the Agent needs to perform arithmetic calculations that the LLM might struggle with or be unreliable at.\n",
    "* **Requirement:** `pip install numexpr` (auxiliary library for Calculator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if not already installed:\n",
    "# pip install numexpr langchain\n",
    "\n",
    "from langchain_community.tools.calculator.tool import Calculator\n",
    "\n",
    "# Initialize Calculator Tool\n",
    "calculator_tool = Calculator()\n",
    "\n",
    "# Example of using the Tool directly\n",
    "# print(calculator_tool.run(\"123 * 456\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. `WikipediaAPIWrapper` (Wikipedia Search)\n",
    "\n",
    "* **Concept:** Allows the Agent to search and retrieve content from Wikipedia.\n",
    "* **When to Use:** When the Agent needs encyclopedic information, definitions, or overviews of topics.\n",
    "* **Requirement:** `pip install wikipedia`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if not already installed:\n",
    "# pip install wikipedia langchain\n",
    "\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain.tools import Tool\n",
    "\n",
    "# Initialize WikipediaAPIWrapper\n",
    "wikipedia_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "\n",
    "# Create Tool from WikipediaAPIWrapper\n",
    "wikipedia_tool = Tool(\n",
    "    name=\"Wikipedia\",\n",
    "    func=wikipedia_wrapper.run,\n",
    "    description=\"Useful when you need to search for information on Wikipedia about concepts, people, or events.\"\n",
    ")\n",
    "\n",
    "# Example of using the Tool directly\n",
    "# print(wikipedia_tool.run(\"LangChain\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. `PythonREPLTool` (Execute Python Code)\n",
    "\n",
    "* **Concept:** Allows the Agent to execute Python code in a REPL (Read-Eval-Print Loop) environment.\n",
    "* **When to Use:** When the Agent needs to perform programming tasks, data analysis, complex string manipulation, or any task that can be solved with Python code.\n",
    "* **Warning:** This is a very powerful tool and poses security risks if not used carefully. It's not recommended to allow an Agent to run arbitrary user-provided code in a production environment without strict security measures.\n",
    "* **Requirement:** `pip install langchain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if not already installed:\n",
    "# pip install langchain\n",
    "\n",
    "from langchain_community.tools.python.tool import PythonREPLTool\n",
    "\n",
    "# Initialize PythonREPLTool\n",
    "python_repl_tool = PythonREPLTool()\n",
    "\n",
    "# Example of using the Tool directly\n",
    "# print(python_repl_tool.run(\"print(2 + 2)\"))\n",
    "# print(python_repl_tool.run(\"import math; print(math.sqrt(16))\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. How to Connect Tools with an Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have defined or initialized your Tools, the next step is to provide them to the Agent. When you initialize an Agent using `create_react_agent` (or other Agent creation functions), you will pass a list of Tool objects to it.\n",
    "\n",
    "The Agent Executor will use the LLM to decide which Tool from this list to invoke based on the user's query and each Tool's description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries if not already installed\n",
    "# pip install langchain-openai openai google-search-results numexpr wikipedia\n",
    "\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_community.utilities import SerpAPIWrapper, WikipediaAPIWrapper\n",
    "from langchain.tools import Tool\n",
    "from langchain_community.tools.calculator.tool import Calculator\n",
    "from langchain_community.tools.python.tool import PythonREPLTool\n",
    "\n",
    "# Set environment variables for OpenAI and SerpAPI keys\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n",
    "# os.environ[\"SERPAPI_API_KEY\"] = \"YOUR_SERPAPI_API_KEY\"\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0) # Lower temperature for more consistent Agent decisions\n",
    "\n",
    "# Initialize Tools\n",
    "search_tool = Tool(\n",
    "    name=\"Google Search\",\n",
    "    func=SerpAPIWrapper().run,\n",
    "    description=\"Useful when you need to search for information on Google about current events or factual data.\"\n",
    ")\n",
    "\n",
    "calculator_tool = Calculator()\n",
    "\n",
    "wikipedia_tool = Tool(\n",
    "    name=\"Wikipedia\",\n",
    "    func=WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=200).run,\n",
    "    description=\"Useful when you need to search for information on Wikipedia about concepts, people, or events.\"\n",
    ")\n",
    "\n",
    "python_repl_tool = PythonREPLTool()\n",
    "\n",
    "# Gather all Tools that the Agent can use\n",
    "tools = [search_tool, calculator_tool, wikipedia_tool, python_repl_tool]\n",
    "\n",
    "# Define Prompt for the Agent\n",
    "# This prompt will instruct the LLM on how to think and use tools\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. You have access to the following tools: {tools}. Use them to answer questions.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"), # To maintain chat history\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"), # For the Agent to record its thoughts and actions\n",
    "])\n",
    "\n",
    "# Create Agent\n",
    "# 'react-json-chat-model' is an Agent type that allows the LLM to think and act (ReAct)\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "# Create Agent Executor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True) # verbose=True to see the Agent's thought process\n",
    "\n",
    "# --- Execute the Agent ---\n",
    "print(\"--- Starting Agent Executor ---\")\n",
    "chat_history = []\n",
    "\n",
    "# Question 1: Requires web search\n",
    "query_1 = \"What's the weather like today in Da Nang?\"\n",
    "print(f\"\\nUser: {query_1}\")\n",
    "response_1 = agent_executor.invoke({\"input\": query_1, \"chat_history\": chat_history})\n",
    "chat_history.extend([HumanMessage(content=query_1), AIMessage(content=response_1[\"output\"])])\n",
    "print(f\"Agent: {response_1['output']}\")\n",
    "\n",
    "# Question 2: Requires calculation\n",
    "query_2 = \"Calculate 15% of 3450.\"\n",
    "print(f\"\\nUser: {query_2}\")\n",
    "response_2 = agent_executor.invoke({\"input\": query_2, \"chat_history\": chat_history})\n",
    "chat_history.extend([HumanMessage(content=query_2), AIMessage(content=response_2[\"output\"])])\n",
    "print(f\"Agent: {response_2['output']}\")\n",
    "\n",
    "# Question 3: Requires Wikipedia search\n",
    "query_3 = \"What is LangChain?\"\n",
    "print(f\"\\nUser: {query_3}\")\n",
    "response_3 = agent_executor.invoke({\"input\": query_3, \"chat_history\": chat_history})\n",
    "chat_history.extend([HumanMessage(content=query_3), AIMessage(content=response_3[\"output\"])])\n",
    "print(f\"Agent: {response_3['output']}\")\n",
    "\n",
    "# Question 4: Requires Python execution\n",
    "query_4 = \"Write a Python code snippet to calculate the factorial of 5.\"\n",
    "print(f\"\\nUser: {query_4}\")\n",
    "response_4 = agent_executor.invoke({\"input\": query_4, \"chat_history\": chat_history})\n",
    "chat_history.extend([HumanMessage(content=query_4), AIMessage(content=response_4[\"output\"])])\n",
    "print(f\"Agent: {response_4['output']}\")\n",
    "\n",
    "print(\"--- Agent Executor Ended ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "* `tools = [...]`: You create a list of Tool objects and pass it to the Agent.\n",
    "* `create_react_agent(llm, tools, prompt)`: This function creates an Agent that uses the ReAct (Reasoning and Acting) prompting strategy with the given Tools and Prompt.\n",
    "* `AgentExecutor(agent=agent, tools=tools, verbose=True)`: The Agent Executor is the orchestrating component. `verbose=True` is very useful for seeing the Agent's thought process and actions.\n",
    "* When you call `agent_executor.invoke(...)`, the Agent will start its reasoning-action loop, select the appropriate Tool, execute it, and use the result to generate the final answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Summary\n",
    "\n",
    "This lesson delved into the concept of **Tools** in LangChain, which are functions or APIs that **Agents** use to extend the LLM's capabilities and interact with the external world. You learned how to **create custom tools** using the `tool` decorator and by inheriting from `BaseTool`. We also explored and practiced using several **common built-in tools** from LangChain such as `SerpAPIWrapper` (web search), `Calculator`, `WikipediaAPIWrapper`, and `PythonREPLTool`. Finally, you saw **how to connect these Tools to an Agent** and how the Agent Executor orchestrates the reasoning-action process to intelligently use tools to solve user problems. Mastering the use of Tools is key to building powerful and flexible Agents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
