{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2.3: Output Parsers\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous lessons, we learned how to create prompts and send them to LLMs to get responses. However, LLMs often return free-form text, without a specific structure. In many applications, we need structured data (e.g., lists, JSON, Python objects) for further processing. This is where **Output Parsers** come into play."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why are Output Parsers Needed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. The Problem with LLM String Output\n",
    "\n",
    "Large Language Models (LLMs) are trained to generate natural language text. When you ask an LLM a question, it will respond with a text string. For example:\n",
    "\n",
    "* **Prompt:** \"List 3 types of fruits.\"\n",
    "* **LLM Response:** \"Apple, Banana, Orange.\" (This is a text string.)\n",
    "\n",
    "If you want to use this list of fruits in your Python code (e.g., to iterate over each fruit), you would have to manually parse this string yourself. This can be complex and error-prone, especially when the LLM's output format might vary slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. The Role of Output Parsers\n",
    "\n",
    "**Output Parsers** in LangChain are tools that help automatically convert the LLM's string output into structured data formats that are easier to use in your code. They act as a bridge between the LLM's free-form text response and the application's need for structured data.\n",
    "\n",
    "* **Benefits:**\n",
    "    * **Automation:** Automatically parses the output, reducing manual coding effort.\n",
    "    * **Reliability:** Ensures output consistently follows a specific format, making your code more stable.\n",
    "    * **Ease of Use:** Converts data into native Python types (list, dict, Pydantic objects) for easy manipulation.\n",
    "    * **Error Handling:** Some parsers can attempt to fix or flag cases where the LLM doesn't perfectly adhere to the format.\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Common Output Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain provides various types of Output Parsers to suit diverse output formatting needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. `StrOutputParser`: Extracting Strings (Default)\n",
    "\n",
    "* **Concept:** This is the simplest and often the default parser. It merely extracts the string content from the LLM's response. If you don't specify any parser, LangChain will typically use `StrOutputParser`.\n",
    "* **When to Use:** When you only need plain text output from the LLM and no special structure is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the library if not already installed\n",
    "# pip install langchain-openai openai\n",
    "\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Set environment variable for OpenAI API key\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "\n",
    "# Define prompt\n",
    "prompt = ChatPromptTemplate.from_template(\"Say 'Hello LangChain!'\")\n",
    "\n",
    "# Build chain with StrOutputParser (can be omitted if it's the default)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Execute chain\n",
    "response = chain.invoke({})\n",
    "print(f\"Response from StrOutputParser: {response}\")\n",
    "print(f\"Data type: {type(response)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. `CommaSeparatedListOutputParser`: Converting to a List\n",
    "\n",
    "* **Concept:** This parser is designed to convert a text string where items are separated by commas into a Python list of strings.\n",
    "* **When to Use:** When you ask the LLM to list items, and you want to receive them as an iterable list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the library if not already installed\n",
    "# pip install langchain-openai openai\n",
    "\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "# Set environment variable for OpenAI API key\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "\n",
    "# Define prompt requesting a comma-separated list of items\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"List 5 common mammals, separated by commas.\"\n",
    ")\n",
    "\n",
    "# Build chain with CommaSeparatedListOutputParser\n",
    "chain = prompt | llm | CommaSeparatedListOutputParser()\n",
    "\n",
    "# Execute chain\n",
    "animals_list = chain.invoke({})\n",
    "print(f\"Response from CommaSeparatedListOutputParser: {animals_list}\")\n",
    "print(f\"Data type: {type(animals_list)}\")\n",
    "print(f\"First item: {animals_list[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. `StructuredOutputParser` and `PydanticOutputParser`: Converting to JSON/Pydantic Objects\n",
    "\n",
    "These are the most powerful parsers, allowing you to define a complex data structure (e.g., a JSON object) and instruct the LLM to generate output according to that structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1. `PydanticOutputParser`\n",
    "\n",
    "* **Concept:** `PydanticOutputParser` uses the `Pydantic` library to define the desired data structure as Python classes. This parser will automatically generate formatting instructions for the LLM and then parse the LLM's output string into a type-checked Pydantic object. If the LLM doesn't adhere to the format, it will attempt to fix it or raise an error.\n",
    "* **When to Use:** When you need complex, reliable, and automatically type-checked structured output. Ideal for information extraction, generating data for databases, or APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the library if not already installed\n",
    "# pip install langchain-openai openai pydantic\n",
    "\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field # Pydantic is the library used to define data structures\n",
    "\n",
    "# Set environment variable for OpenAI API key\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0) # temperature=0 for more consistent output\n",
    "\n",
    "# 1. Define the desired data structure using Pydantic BaseModel\n",
    "class PersonInfo(BaseModel):\n",
    "    name: str = Field(description=\"Full name of the person\")\n",
    "    age: int = Field(description=\"Age of the person\")\n",
    "    occupation: str = Field(description=\"Current occupation of the person\")\n",
    "    hobbies: list[str] = Field(description=\"List of the person's hobbies\")\n",
    "\n",
    "# 2. Initialize PydanticOutputParser with the defined structure\n",
    "parser = PydanticOutputParser(pydantic_object=PersonInfo)\n",
    "\n",
    "# 3. Define Prompt Template\n",
    "# Crucial: Include formatting instructions from the parser into the prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an information extraction assistant. Extract the following person's information based on the format:\\n{format_instructions}\"),\n",
    "    (\"human\", \"Extract information from the text: 'My name is John Doe, I am 30 years old and a software engineer. I like reading books and playing games.'\")\n",
    "]).partial(format_instructions=parser.get_format_instructions()) # Add formatting instructions to the prompt\n",
    "\n",
    "# 4. Build chain\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# 5. Execute chain\n",
    "person_info = chain.invoke({})\n",
    "print(f\"Response from PydanticOutputParser:\")\n",
    "print(f\"Name: {person_info.name}\")\n",
    "print(f\"Age: {person_info.age}\")\n",
    "print(f\"Occupation: {person_info.occupation}\")\n",
    "print(f\"Hobbies: {person_info.hobbies}\")\n",
    "print(f\"Data type of hobbies: {type(person_info.hobbies)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "* `BaseModel` and `Field` from `pydantic`: Used to define data fields and their types. `description` in `Field` is crucial as it provides context to the LLM about the meaning of each field.\n",
    "* `parser.get_format_instructions()`: This method generates a detailed instruction string for the LLM on how to format the output (e.g., requesting JSON with specific fields). This string is then injected into the prompt.\n",
    "* `chain = prompt | llm | parser`: The LLM will attempt to generate output according to the instructions, and the `parser` will attempt to parse that string into a `PersonInfo` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2. `StructuredOutputParser` (Note: Largely superseded by PydanticOutputParser)\n",
    "\n",
    "* **Concept:** `StructuredOutputParser` is an older parser in LangChain, also used for extracting structured data. It typically requires you to define the output structure using `ResponseSchema` objects and `StructuredOutputParser.from_response_schemas`.\n",
    "* **Relationship:** While still existing, `PydanticOutputParser` is recommended over it because it leverages the power of Pydantic for better type checking and error handling. You can consider `PydanticOutputParser` as a more advanced and specialized version of the `StructuredOutputParser` idea. We will focus on `PydanticOutputParser` due to its modernity and effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Practical Example: Using Output Parsers to Get Structured Data from LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've practiced individual examples above. Now, let's try a more comprehensive example to see the power of combining `PromptTemplate`, LLM, and `OutputParser`.\n",
    "\n",
    "**Goal:** Build a chain to extract movie information from a text snippet and format it into a Python object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the library if not already installed\n",
    "# pip install langchain-openai openai pydantic\n",
    "\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# Set environment variable for OpenAI API key\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# 1. Define the data structure for movie information\n",
    "class MovieInfo(BaseModel):\n",
    "    title: str = Field(description=\"Title of the movie\")\n",
    "    release_year: int = Field(description=\"Release year of the movie\")\n",
    "    director: str = Field(description=\"Name of the movie's director\")\n",
    "    main_actors: List[str] = Field(description=\"List of main actors\")\n",
    "    genres: List[str] = Field(description=\"List of movie genres\")\n",
    "    imdb_score: float = Field(description=\"IMDb score of the movie\")\n",
    "\n",
    "# 2. Initialize PydanticOutputParser\n",
    "parser_movie = PydanticOutputParser(pydantic_object=MovieInfo)\n",
    "\n",
    "# 3. Define Prompt Template with formatting instructions\n",
    "prompt_movie = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a movie information extraction assistant. Extract the following information based on the format:\\n{format_instructions}\"),\n",
    "    (\"human\", \"Extract movie information from the following text:\\n{movie_text}\")\n",
    "]).partial(format_instructions=parser_movie.get_format_instructions())\n",
    "\n",
    "# 4. Build chain\n",
    "chain_movie = prompt_movie | llm | parser_movie\n",
    "\n",
    "# 5. Input text\n",
    "movie_text = \"\"\"\n",
    "The movie \"The Shawshank Redemption\" was released in 1994, directed by Frank Darabont.\n",
    "Main actors include Tim Robbins and Morgan Freeman.\n",
    "The film belongs to the Drama genre. Its IMDb score is 9.3.\n",
    "\"\"\"\n",
    "\n",
    "# 6. Execute chain\n",
    "try:\n",
    "    extracted_movie_info = chain_movie.invoke({\"movie_text\": movie_text})\n",
    "\n",
    "    print(f\"--- Extracted Movie Information ---\")\n",
    "    print(f\"Title: {extracted_movie_info.title}\")\n",
    "    print(f\"Release Year: {extracted_movie_info.release_year}\")\n",
    "    print(f\"Director: {extracted_movie_info.director}\")\n",
    "    print(f\"Main Actors: {', '.join(extracted_movie_info.main_actors)}\")\n",
    "    print(f\"Genres: {', '.join(extracted_movie_info.genres)}\")\n",
    "    print(f\"IMDb Score: {extracted_movie_info.imdb_score}\")\n",
    "    print(f\"Data type of object: {type(extracted_movie_info)}\")\n",
    "    print(f\"Data type of main actors: {type(extracted_movie_info.main_actors)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while extracting movie information: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Notes:**\n",
    "* The accuracy of information extraction depends on the LLM's capabilities and the clarity of the prompt/formatting instructions.\n",
    "* With `PydanticOutputParser`, if the LLM returns an invalid format, the parser will attempt to fix it. If it cannot, it will raise an error, letting you know when the output is not structured correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Summary\n",
    "\n",
    "This lesson explained the importance of **Output Parsers** in converting the LLM's free-form string output into structured data formats that are easy to use in Python code. We learned about common parser types:\n",
    "* **`StrOutputParser`** for simple string extraction.\n",
    "* **`CommaSeparatedListOutputParser`** for converting strings into lists of items.\n",
    "* **`PydanticOutputParser`** (recommended) for extracting complex data into Python objects defined with `Pydantic BaseModel`, ensuring data type integrity.\n",
    "\n",
    "Through practical examples, you've seen how to integrate Output Parsers into LangChain chains using LCEL to obtain structured data from LLMs, opening up possibilities for building more reliable and powerful LLM applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
