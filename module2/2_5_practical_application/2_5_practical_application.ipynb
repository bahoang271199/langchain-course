{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2.5: Practical Application - Building a Content Generation App\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous lessons, we explored the core components of LangChain such as **Prompts**, **Models**, **Output Parsers**, and how to connect them into **Chains** using **LangChain Expression Language (LCEL)**. This lesson will be a comprehensive practical exercise where you will apply all that knowledge to build a simple but useful application: a content generation tool for blog posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Applying Learned Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This content generation application will illustrate how you can chain multiple LLM tasks together to achieve a larger goal. Specifically, we will use:\n",
    "\n",
    "* **`ChatPromptTemplate`**: To guide the LLM for each specific task.\n",
    "* **`ChatOpenAI` (or `ChatGoogleGenerativeAI`)**: As the main language model.\n",
    "* **`StrOutputParser`**: To extract string responses.\n",
    "* **`CommaSeparatedListOutputParser`**: To receive a list of ideas.\n",
    "* **LCEL (`|`, `RunnableParallel`)**: To efficiently connect sequential processing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Designing the Content Generation Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our application will perform three main steps, each being a separate Chain, which are then connected sequentially:\n",
    "\n",
    "1.  **Idea Generation:** Based on an input topic, the LLM will suggest a few blog post ideas.\n",
    "2.  **Outline Development:** Choosing one idea from step 1, the LLM will generate a detailed outline for that blog post.\n",
    "3.  **Introduction Writing:** Based on the generated outline, the LLM will write an engaging introductory paragraph for the blog post.\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building the Application Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, ensure you have installed the necessary libraries and set up your API keys as learned in Lesson 1.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the library if not already installed\n",
    "# pip install langchain-openai openai pydantic\n",
    "\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessage, SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser, CommaSeparatedListOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "\n",
    "# Set environment variable for OpenAI API key\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "# Initialize Chat Model\n",
    "# Use a lower temperature for more stable and less randomly creative output\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Step 1: Generate Blog Post Ideas Based on a Topic\n",
    "\n",
    "We will ask the LLM to provide a list of ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Goal:** Get 3-5 blog post ideas on a specific topic.\n",
    "* **Input:** `topic` (blog post topic).\n",
    "* **Output:** A list of ideas.\n",
    "* **Components:** `ChatPromptTemplate` -> `llm` -> `CommaSeparatedListOutputParser`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Chain 1: Generate blog ideas ---\n",
    "idea_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"You are a content marketing expert. Suggest 5 engaging blog post ideas about the following topic, separated by commas.\"),\n",
    "    HumanMessage(content=\"Topic: {topic}\"),\n",
    "])\n",
    "\n",
    "idea_chain = idea_prompt | llm | CommaSeparatedListOutputParser()\n",
    "\n",
    "# Test Chain 1 independently\n",
    "# topic_test = \"artificial intelligence in education\"\n",
    "# ideas_test = idea_chain.invoke({\"topic\": topic_test})\n",
    "# print(f\"Blog ideas for '{topic_test}': {ideas_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Step 2: Develop a Detailed Outline for the Chosen Idea\n",
    "\n",
    "After getting ideas, we will choose one and ask the LLM to develop an outline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Goal:** Create a detailed outline (including sections, subheadings) for a blog post idea.\n",
    "* **Input:** `blog_idea` (the chosen blog idea).\n",
    "* **Output:** Free-form text outline.\n",
    "* **Components:** `ChatPromptTemplate` -> `llm` -> `StrOutputParser`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Chain 2: Develop detailed outline ---\n",
    "outline_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"You are a content editor. Create a detailed outline for the following blog post. The outline should include an introduction, main sections, subsections, and a conclusion.\"),\n",
    "    HumanMessage(content=\"Blog post idea: {blog_idea}\"),\n",
    "])\n",
    "\n",
    "outline_chain = outline_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Test Chain 2 independently\n",
    "# idea_test = \"How AI Personalizes Learning Experiences\"\n",
    "# outline_test = outline_chain.invoke({\"blog_idea\": idea_test})\n",
    "# print(f\"\\nOutline for '{idea_test}':\\n{outline_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Step 3: Write an Introductory Paragraph for the Blog Post\n",
    "\n",
    "Finally, we will use the outline to write the introductory paragraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Goal:** Write an engaging introductory paragraph based on the outline.\n",
    "* **Input:** `blog_outline` (detailed outline).\n",
    "* **Output:** Text introduction.\n",
    "* **Components:** `ChatPromptTemplate` -> `llm` -> `StrOutputParser`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Chain 3: Write blog post introduction ---\n",
    "intro_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"You are a professional writer. Based on the following outline, write an engaging and captivating introductory paragraph for the blog post. The introduction should introduce the topic and hook the reader.\"),\n",
    "    HumanMessage(content=\"Blog post outline:\\n{blog_outline}\"),\n",
    "])\n",
    "\n",
    "intro_chain = intro_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Test Chain 3 independently\n",
    "# outline_example = \"\"\"\n",
    "# I. Introduction\n",
    "#    A. Opening on AI and education\n",
    "#    B. Importance of personalized learning\n",
    "# II. How AI personalizes learning?\n",
    "#    A. Analyzing learning data\n",
    "#    B. Content recommendation systems\n",
    "#    C. Instant feedback\n",
    "# III. Benefits of AI in personalization\n",
    "#    A. Enhanced learning effectiveness\n",
    "#    B. Reduced teacher workload\n",
    "# IV. Challenges and future\n",
    "#    A. Ethical and privacy issues\n",
    "#    B. Future development\n",
    "# V. Conclusion\n",
    "# \"\"\"\n",
    "# intro_test = intro_chain.invoke({\"blog_outline\": outline_example})\n",
    "# print(f\"\\nIntroduction:\\n{intro_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Connecting Steps into a Sequential Chain using LCEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will connect these three small Chains into a larger sequential chain using LCEL. We will use `RunnableParallel` to manage inputs and pass results between steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Connect the entire application using LCEL ---\n",
    "\n",
    "# Step 1: Idea Generation\n",
    "# Input: {\"topic\": \"...\"}\n",
    "# Output: list of ideas (e.g., [\"idea1\", \"idea2\", \"idea3\"])\n",
    "# We will select the first idea from this list to proceed\n",
    "full_content_chain = (\n",
    "    {\"ideas\": idea_chain, \"original_topic\": RunnablePassthrough()} # Run idea_chain and retain original topic\n",
    "    | RunnableParallel(\n",
    "        # Get the first idea from the ideas list to use as input for outline_chain\n",
    "        blog_idea=lambda x: x[\"ideas\"][0],\n",
    "        # Retain the original topic for later use if needed\n",
    "        original_topic=lambda x: x[\"original_topic\"]\n",
    "    )\n",
    "    | RunnableParallel(\n",
    "        # Run outline_chain with blog_idea\n",
    "        blog_outline=outline_chain,\n",
    "        # Pass through blog_idea and original_topic\n",
    "        blog_idea=lambda x: x[\"blog_idea\"],\n",
    "        original_topic=lambda x: x[\"original_topic\"]\n",
    "    )\n",
    "    | RunnableParallel(\n",
    "        # Run intro_chain with blog_outline\n",
    "        blog_intro=intro_chain,\n",
    "        # Pass through blog_outline, blog_idea, original_topic\n",
    "        blog_outline=lambda x: x[\"blog_outline\"],\n",
    "        blog_idea=lambda x: x[\"blog_idea\"],\n",
    "        original_topic=lambda x: x[\"original_topic\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Data flow notes:\n",
    "# 1. The initial input for `full_content_chain.invoke()` is a dictionary, e.g., `{\"topic\": \"...\"}`.\n",
    "# 2. The first step `{\"ideas\": idea_chain, \"original_topic\": RunnablePassthrough()}`\n",
    "#    - `idea_chain` receives `{\"topic\": ...}` and generates `ideas` (list of strings).\n",
    "#    - `RunnablePassthrough()` receives the entire original input and assigns it to `original_topic`.\n",
    "#    - The output of this step is `{\"ideas\": [\"...\", \"...\"], \"original_topic\": {\"topic\": \"...\"}}`.\n",
    "# 3. The second step `| RunnableParallel(blog_idea=lambda x: x[\"ideas\"][0], ...)`\n",
    "#    - Takes `ideas[0]` from the previous output and assigns it to `blog_idea`.\n",
    "#    - Passes `original_topic` through.\n",
    "#    - The output of this step is `{\"blog_idea\": \"...\", \"original_topic\": {\"topic\": \"...\"}}`.\n",
    "# 4. The third step `| RunnableParallel(blog_outline=outline_chain, ...)`\n",
    "#    - `outline_chain` receives `{\"blog_idea\": ...}` and generates `blog_outline`.\n",
    "#    - Passes `blog_idea` and `original_topic` through.\n",
    "#    - The output of this step is `{\"blog_outline\": \"...\", \"blog_idea\": \"...\", \"original_topic\": {\"topic\": \"...\"}}`.\n",
    "# 5. The fourth step `| RunnableParallel(blog_intro=intro_chain, ...)`\n",
    "#    - `intro_chain` receives `{\"blog_outline\": ...}` and generates `blog_intro`.\n",
    "#    - Passes `blog_outline`, `blog_idea`, `original_topic` through.\n",
    "#    - The final output is a dictionary containing `blog_intro`, `blog_outline`, `blog_idea`, `original_topic`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Executing the Content Generation Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will run the entire chain with a specific topic and observe the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the entire chain\n",
    "blog_topic = \"future of work and AI\"\n",
    "\n",
    "print(f\"--- Generating blog content on topic: '{blog_topic}' ---\")\n",
    "full_response = full_content_chain.invoke({\"topic\": blog_topic})\n",
    "\n",
    "print(\"\\n--- Suggested blog ideas ---\")\n",
    "# Note: full_response['ideas'] would be the list of ideas from the first step\n",
    "# However, in the chain, we only took ideas[0] to pass into blog_idea.\n",
    "# To display all ideas, you would need to adjust RunnableParallel or run idea_chain separately.\n",
    "# Here, we'll assume the first idea was chosen.\n",
    "print(f\"Selected idea: {full_response['blog_idea']}\")\n",
    "\n",
    "print(\"\\n--- Detailed Outline ---\")\n",
    "print(full_response[\"blog_outline\"])\n",
    "\n",
    "print(\"\\n--- Blog Post Introduction ---\")\n",
    "print(full_response[\"blog_intro\"])\n",
    "\n",
    "print(\"\\n--- Completed ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try changing the `blog_topic` and re-running the program to see different content generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Summary\n",
    "\n",
    "This lesson provided a comprehensive practical exercise on building a simple content generation application using LangChain. We applied our knowledge of **Prompts**, **Models**, **Output Parsers**, and **LangChain Expression Language (LCEL)** to create a sequential processing chain consisting of three steps: **generating blog post ideas**, **developing a detailed outline**, and **writing an introductory paragraph**. By using the `|` operator and `RunnableParallel`, we effectively connected these smaller Chains, illustrating how data flows through the steps and how you can build more complex workflows with LangChain. This practical exercise is a crucial step for you to start designing and deploying your own LLM applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
