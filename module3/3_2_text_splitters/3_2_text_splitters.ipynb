{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 3.2: Text Splitters\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous lesson, we learned how to load data from various sources into LangChain as `Document` objects. However, these documents can be very long, exceeding the token limits of Large Language Models (LLMs) or reducing the efficiency of search tasks. This is where **Text Splitters** come into play."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why is Splitting Large Texts (Chunking) Necessary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. LLM Token Limits\n",
    "\n",
    "Each LLM has a limit on the number of tokens (words or parts of words) it can process in a single API call. If a document is too long, you cannot send its entire content to the LLM.\n",
    "\n",
    "* **Problems:**\n",
    "    * **Exceeding limit error:** The LLM will refuse to process if the prompt exceeds `max_tokens`.\n",
    "    * **High cost:** Even if not exceeding the limit, sending too many tokens will be more expensive.\n",
    "    * **Reduced performance:** The LLM can be \"overwhelmed\" by large amounts of information, leading to less accurate or irrelevant responses.\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Search Optimization (Retrieval)\n",
    "\n",
    "In RAG (Retrieval-Augmented Generation) systems, when you search for relevant information, you want to retrieve small, precise text snippets containing the necessary context. If you store entire long documents in a vector database, searching will be less efficient:\n",
    "\n",
    "* **Low accuracy:** A long document might contain multiple topics. When searching for a specific topic, you might retrieve the entire document, including irrelevant parts.\n",
    "* **Costly and slow:** Embedding and searching on large text blocks will consume more resources and time.\n",
    "* **\"Lost in the middle\":** Even if a large document is retrieved, the LLM might miss crucial information if it's located in the middle of a very long text segment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. The Role of Text Splitters (Chunking)\n",
    "\n",
    "**Text Splitters** are tools in LangChain that help break down large documents into smaller text segments, called **chunks**. This process is known as **chunking**.\n",
    "\n",
    "* **Benefits:**\n",
    "    * **Adhere to token limits:** Ensures each chunk is small enough to fit within the LLM's token limit.\n",
    "    * **Improve search:** Smaller chunks enable more precise semantic search, as each chunk focuses on a specific topic or idea.\n",
    "    * **Optimize cost:** Reduces the number of tokens needed to send to the LLM for each query.\n",
    "    * **Easy to manage:** Smaller chunks are easier to store, embed, and process.\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Splitting Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting text is not just about cutting strings by a certain number of characters. The goal is to split text \"intelligently\" so that chunks still retain semantic meaning. LangChain offers various text splitting strategies.\n",
    "\n",
    "To run the examples below, ensure you have installed the `langchain` library and other dependencies if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the library if not already installed:\n",
    "# pip install langchain\n",
    "# pip install tiktoken # To estimate tokens for some splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. `CharacterTextSplitter`: Splitting by Character\n",
    "\n",
    "* **Concept:** This is the simplest splitter. It splits text based on a set of separator characters (default is `[\"\\n\\n\", \"\\n\", \" \", \"\"]`, meaning it prioritizes paragraphs, then lines, words, and finally characters). It tries to create chunks as close to `chunk_size` as possible.\n",
    "* **When to Use:** When you need a basic splitting method and are not overly concerned with preserving complex semantic structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text = \"\"\"\n",
    "Artificial intelligence (AI) is changing the world.\n",
    "It includes machine learning and deep learning.\n",
    "\n",
    "LangChain is a powerful framework.\n",
    "It helps build LLM applications.\n",
    "\"\"\"\n",
    "\n",
    "# Initialize CharacterTextSplitter\n",
    "# chunk_size: maximum size of each chunk (in characters)\n",
    "# chunk_overlap: number of overlapping characters between adjacent chunks\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\", # Prioritize splitting by paragraph\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len, # Function to calculate length (default is len)\n",
    "    is_separator_regex=False # Is it a regex?\n",
    ")\n",
    "\n",
    "chunks = splitter.split_text(text)\n",
    "\n",
    "print(\"--- CharacterTextSplitter ---\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1} (len={len(chunk)}):\\n'{chunk}'\\n---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. `RecursiveCharacterTextSplitter`: Recursive Splitting, Attempting to Maintain Meaningful Chunks\n",
    "\n",
    "* **Concept:** This is the recommended and most commonly used splitter. It attempts to split text more intelligently by using a list of separator characters (default is `[\"\\n\\n\", \"\\n\", \" \", \"\"]`). It will try to split by the first separator. If the chunk is still too large, it will try the next separator, and so on, until the chunks reach the desired size. This helps maintain context by avoiding cutting in the middle of a sentence or paragraph.\n",
    "* **When to Use:** Most cases, especially when you need to preserve the context and structure of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text = \"\"\"\n",
    "# Main Article Title\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This is a long paragraph about the importance of artificial intelligence in modern life. AI is changing the way we work, learn, and entertain ourselves. It is not just a technology but also a driving force for innovation globally.\n",
    "\n",
    "### Benefits of AI\n",
    "\n",
    "AI brings many significant benefits, from automating repetitive tasks to providing deep insights from big data. It helps improve efficiency, reduce costs, and unlock new possibilities that were previously unattainable.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In summary, AI is a promising field with immense potential. Understanding and applying AI correctly will be key to future development.\n",
    "\"\"\"\n",
    "\n",
    "# Initialize RecursiveCharacterTextSplitter\n",
    "# It will try to split by \"\\n\\n\", then \"\\n\", then \" \", then \"\"\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200, # Maximum size of each chunk\n",
    "    chunk_overlap=20, # Number of overlapping characters between chunks\n",
    "    length_function=len,\n",
    "    add_start_index=True # Add start index of chunk to metadata\n",
    ")\n",
    "\n",
    "chunks = splitter.split_text(text)\n",
    "\n",
    "print(\"--- RecursiveCharacterTextSplitter ---\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1} (len={len(chunk)}, start_index={chunk.metadata.get('start_index')}):\\n'{chunk.page_content}'\\n---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "* `chunk_size`: The maximum size of each chunk.\n",
    "* `chunk_overlap`: The number of characters (or tokens) that adjacent chunks will overlap. This helps maintain context when an idea might span across a chunk boundary.\n",
    "* `length_function`: The function used to calculate the length of the chunk. Default is `len` (number of characters). For LLM models, you might want to use a token counting function.\n",
    "* `add_start_index`: Adds the starting index of the chunk in the original document to the metadata, useful for debugging or provenance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Specialized Splitters: `MarkdownTextSplitter`, `PythonCodeTextSplitter`\n",
    "\n",
    "LangChain also provides splitters designed to understand the semantic structure or specific formatting of certain text types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Concept:** These splitters use knowledge of the language's or format's syntax (e.g., Markdown, Python) to split text more intelligently, trying not to cut in the middle of code blocks, headings, lists, etc.\n",
    "* **When to Use:** When you are working with clearly structured document types like source code, Markdown documents, HTML, etc.\n",
    "* **Requirement:** Some specialized splitters might require additional library installations (e.g., `tiktoken` for token-based splitters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownTextSplitter, PythonCodeTextSplitter\n",
    "\n",
    "# Example MarkdownTextSplitter\n",
    "markdown_text = \"\"\"\n",
    "# Main Title\n",
    "\n",
    "This is the introduction paragraph.\n",
    "\n",
    "## Section 1: Introduction\n",
    "- Item A\n",
    "- Item B\n",
    "\n",
    "### Subsection 1.1\n",
    "\n",
    "This is the content of the subsection.\n",
    "\n",
    "```python\n",
    "def hello_world():\n",
    "    print(\"Hello, World!\")\n",
    "```\n",
    "\n",
    "## Section 2: Conclusion\n",
    "\"\"\"\n",
    "\n",
    "markdown_splitter = MarkdownTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "markdown_chunks = markdown_splitter.split_text(markdown_text)\n",
    "\n",
    "print(\"--- MarkdownTextSplitter ---\")\n",
    "for i, chunk in enumerate(markdown_chunks):\n",
    "    print(f\"Chunk {i+1} (len={len(chunk)}):\\n'{chunk}'\\n---\")\n",
    "\n",
    "# Example PythonCodeTextSplitter\n",
    "python_code = \"\"\"\n",
    "import os\n",
    "\n",
    "class MyClass:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def greet(self):\n",
    "        return f\"Hello, {self.name}!\"\n",
    "\n",
    "def main():\n",
    "    obj = MyClass(\"LangChain\")\n",
    "    print(obj.greet())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "\n",
    "python_splitter = PythonCodeTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "python_chunks = python_splitter.split_text(python_code)\n",
    "\n",
    "print(\"\\n--- PythonCodeTextSplitter ---\")\n",
    "for i, chunk in enumerate(python_chunks):\n",
    "    print(f\"Chunk {i+1} (len={len(chunk)}):\\n'{chunk}'\\n---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Importance of `chunk_size` and `chunk_overlap`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two parameters are extremely important when splitting text and need to be carefully adjusted depending on your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. `chunk_size`\n",
    "\n",
    "* **Concept:** The maximum size (in characters or tokens) that each text segment (chunk) is allowed to have.\n",
    "* **Impact:**\n",
    "    * **Small `chunk_size`:** More chunks, each focusing on a small idea. Good for very specific searches, but can lose context if a large idea is split.\n",
    "    * **Large `chunk_size`:** Fewer chunks, each containing more context. Good for capturing overall ideas, but can exceed LLM token limits or reduce search accuracy if the chunk is too broad.\n",
    "* **Selection:** Needs to balance the LLM's token limit and the need for context. For common LLMs, a `chunk_size` of 500-1500 tokens is often a good starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. `chunk_overlap`\n",
    "\n",
    "* **Concept:** The number of characters (or tokens) that adjacent chunks will overlap.\n",
    "* **Impact:**\n",
    "    * **Small/no `chunk_overlap`:** Chunks are completely separate. Can lead to loss of context if an important sentence or idea spans the boundary between two chunks.\n",
    "    * **Large `chunk_overlap`:** Chunks have a lot of overlapping information. Ensures context is maintained, but can lead to redundancy and increased embedding/search costs.\n",
    "* **Selection:** Often set to 10-20% of `chunk_size`. The goal is to ensure that important ideas are not cut off and context is preserved when transitioning from one chunk to another.\n",
    "\n",
    "[Image illustrating chunk_size and chunk_overlap visually]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Practical Example: Splitting Loaded Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the documents loaded from Lesson 3.1 and apply `RecursiveCharacterTextSplitter` to split them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all necessary libraries for this example\n",
    "# pip install langchain pypdf beautifulsoup4 tiktoken reportlab\n",
    "\n",
    "import os\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader, WebBaseLoader, CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# --- Prepare sample files (similar to Lesson 3.1) ---\n",
    "txt_content = \"This is important information from a text note.\\nIt talks about the benefits of learning programming.\"\n",
    "with open(\"note.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(txt_content)\n",
    "\n",
    "csv_content = \"Product,Price,Quantity\\nLaptop,1200,50\\nPhone,800,120\\nHeadphones,50,300\"\n",
    "with open(\"products.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(csv_content)\n",
    "\n",
    "pdf_test_path = \"document.pdf\"\n",
    "try:\n",
    "    from reportlab.pdfgen import canvas\n",
    "    c = canvas.Canvas(pdf_test_path)\n",
    "    c.drawString(100, 750, \"This is content from a sample PDF file.\")\n",
    "    c.drawString(100, 730, \"It is generated for illustration purposes.\")\n",
    "    c.save()\n",
    "except ImportError:\n",
    "    with open(pdf_test_path, \"w\") as f:\n",
    "        f.write(\"This is a dummy PDF file. Please replace with a real PDF.\\n\")\n",
    "    print(\"Could not create real PDF. Using dummy file.\")\n",
    "\n",
    "# --- Load data using different loaders ---\n",
    "all_documents = []\n",
    "\n",
    "print(\"Loading documents...\")\n",
    "txt_loader = TextLoader(\"note.txt\", encoding=\"utf-8\")\n",
    "all_documents.extend(txt_loader.load())\n",
    "\n",
    "csv_loader = CSVLoader(\"products.csv\", encoding=\"utf-8\")\n",
    "all_documents.extend(csv_loader.load())\n",
    "\n",
    "web_loader = WebBaseLoader(\"https://www.langchain.com/blog\")\n",
    "try:\n",
    "    all_documents.extend(web_loader.load())\n",
    "except Exception as e:\n",
    "    print(f\"Error loading from web: {e}. Skipping web load.\")\n",
    "\n",
    "try:\n",
    "    pdf_loader = PyPDFLoader(pdf_test_path)\n",
    "    all_documents.extend(pdf_loader.load())\n",
    "except Exception as e:\n",
    "    print(f\"Error loading from PDF: {e}. Skipping PDF load.\")\n",
    "\n",
    "print(f\"Total original documents loaded: {len(all_documents)}\\n\")\n",
    "\n",
    "# --- Split documents using RecursiveCharacterTextSplitter ---\n",
    "print(\"Splitting documents...\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, # Desired chunk size\n",
    "    chunk_overlap=50, # Overlap\n",
    "    length_function=len, # Calculate length by characters\n",
    "    add_start_index=True # Add start index to metadata\n",
    ")\n",
    "\n",
    "# split_documents() takes a list of Documents and returns a list of split Documents\n",
    "chunks = text_splitter.split_documents(all_documents)\n",
    "\n",
    "print(f\"Total chunks after splitting: {len(chunks)}\\n\")\n",
    "\n",
    "print(\"--- Split chunks (a few examples) ---\")\n",
    "for i, chunk in enumerate(chunks[:5]): # Print first 5 chunks for illustration\n",
    "    print(f\"Chunk {i+1}:\")\n",
    "    print(f\"  Content (partial): {chunk.page_content[:200]}...\")\n",
    "    print(f\"  Length: {len(chunk.page_content)}\")\n",
    "    print(f\"  Metadata: {chunk.metadata}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "# --- Clean up sample files ---\n",
    "os.remove(\"note.txt\")\n",
    "os.remove(\"products.csv\")\n",
    "os.remove(pdf_test_path)\n",
    "print(\"\\nSample files removed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "This example illustrates a complete process:\n",
    "1.  Load documents from various sources using Document Loaders.\n",
    "2.  Use `RecursiveCharacterTextSplitter` to split all loaded documents into chunks with desired size and overlap.\n",
    "3.  Print information about the split chunks, including content, length, and metadata (including `start_index` if enabled).\n",
    "\n",
    "This splitting process is an essential step before creating embeddings and storing them in a Vector Store, ensuring that the embedded and retrieved text segments are optimal for the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Summary\n",
    "\n",
    "This lesson explained why it's necessary to **split large texts (chunking)** in LLM applications, primarily to address **LLM token limits** and **optimize search efficiency**. We explored various **text splitting strategies** in LangChain:\n",
    "* **`CharacterTextSplitter`** for simple character-based splitting.\n",
    "* **`RecursiveCharacterTextSplitter`** (recommended) for more intelligent splitting, attempting to preserve context.\n",
    "* Specialized splitters like **`MarkdownTextSplitter`** and **`PythonCodeTextSplitter`** for splitting by semantic structure.\n",
    "\n",
    "The lesson also emphasized the **importance of `chunk_size` and `chunk_overlap`**, two key parameters affecting the size and overlap of text segments, and how to adjust them for optimal performance. Finally, a practical example illustrated how to apply `RecursiveCharacterTextSplitter` to split loaded documents, laying a solid foundation for the next steps in building RAG systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
