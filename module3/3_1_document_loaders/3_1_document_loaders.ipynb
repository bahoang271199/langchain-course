{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 3.1: Document Loaders\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build practical Large Language Model (LLM) applications, especially Question Answering (Q&A) systems or knowledge-intensive chatbots, LLMs need access to information not present in their initial training data. This data can be scattered across various formats: text files, PDFs, web pages, databases, etc. **Document Loaders** in LangChain are tools that help you load this data into a format that LangChain can understand and process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Document Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. What are Document Loaders?\n",
    "\n",
    "**Document Loaders** are classes in LangChain designed to load data from external sources and transform them into **`Document`** objects that LangChain can work with. This is the first and most crucial step in bringing your own data into LLM applications.\n",
    "\n",
    "* **Relationship:** Document Loaders are the foundation for **Retrieval-Augmented Generation (RAG)** systems, where LLMs need to retrieve information from a specific data store to generate accurate and contextual answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. The `Document` Object in LangChain\n",
    "\n",
    "When data is loaded by a Document Loader, it is converted into one or more `Document` objects. Each `Document` object has two main attributes:\n",
    "\n",
    "* **`page_content`:** A string containing the actual text content of the document (or a part of it).\n",
    "* **`metadata`:** A dictionary containing additional information about the document, such as its source, page number, author, creation date, etc. Metadata is very useful for tracking the origin of information or filtering documents.\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Why are Document Loaders Important?\n",
    "\n",
    "* **Diverse Data Integration:** Allows you to work with data from almost any source without writing complex parsing code from scratch.\n",
    "* **Format Standardization:** Converts all data types into a unified `Document` format, making subsequent processing steps (like text splitting, embedding generation) easier.\n",
    "* **RAG Support:** An essential step for building RAG systems, enabling LLMs to access and utilize external knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Common Document Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain provides a rich library of Document Loaders for various data formats and sources. Here are some of the most common types:\n",
    "\n",
    "To run the examples below, ensure your virtual environment is activated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the library if not already installed:\n",
    "# pip install langchain\n",
    "# Specific packages for each loader will be listed below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. `TextLoader`: Loading `.txt` Files\n",
    "\n",
    "* **Concept:** `TextLoader` is the most basic loader, used to load content from plain text files (`.txt`).\n",
    "* **When to Use:** When you have simple text data stored in `.txt` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if not already installed:\n",
    "# pip install langchain\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "import os\n",
    "\n",
    "# Create a sample text file\n",
    "file_path_txt = \"sample.txt\"\n",
    "with open(file_path_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"This is a sample text document.\\n\")\n",
    "    f.write(\"It contains information about Document Loaders in LangChain.\\n\")\n",
    "    f.write(\"This is the third line of the text file.\")\n",
    "\n",
    "# Initialize TextLoader and load documents\n",
    "loader = TextLoader(file_path_txt, encoding=\"utf-8\")\n",
    "documents_txt = loader.load()\n",
    "\n",
    "print(f\"--- Content from TextLoader ({file_path_txt}) ---\")\n",
    "for doc in documents_txt:\n",
    "    print(f\"Content: {doc.page_content[:50]}...\") # Print first 50 characters\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "# Clean up sample file\n",
    "os.remove(file_path_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. `PyPDFLoader`: Loading PDF Files\n",
    "\n",
    "* **Concept:** `PyPDFLoader` uses the `pypdf` library to extract text from PDF files. It can extract text from individual pages.\n",
    "* **When to Use:** When you need to process information from PDF documents.\n",
    "* **Requirement:** Requires the `pypdf` library: `pip install pypdf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if not already installed:\n",
    "# pip install pypdf langchain\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import os\n",
    "\n",
    "# Create a sample PDF file (in reality, you need an existing PDF file)\n",
    "# For illustration, you can download any small PDF file into this directory\n",
    "# Example: sample.pdf\n",
    "# Or create a dummy PDF file (without actual content) to prevent code errors\n",
    "# (Note: To create a real PDF, more complex libraries like reportlab are needed)\n",
    "# For simplicity, assume you have a \"sample.pdf\" in the same directory.\n",
    "pdf_file_path = \"sample.pdf\"\n",
    "# Create a dummy file so the code runs without a real PDF file\n",
    "# In a real-world scenario, you'd place a valid PDF file here.\n",
    "with open(pdf_file_path, \"w\") as f:\n",
    "    f.write(\"This is just a dummy PDF file, not a real PDF.\\n\")\n",
    "    f.write(\"Please replace with a valid PDF file for testing.\")\n",
    "\n",
    "try:\n",
    "    # Initialize PyPDFLoader and load documents\n",
    "    loader = PyPDFLoader(pdf_file_path)\n",
    "    documents_pdf = loader.load()\n",
    "\n",
    "    print(f\"--- Content from PyPDFLoader ({pdf_file_path}) ---\")\n",
    "    if documents_pdf:\n",
    "        for i, doc in enumerate(documents_pdf):\n",
    "            print(f\"Page {i+1} - Content: {doc.page_content[:50]}...\")\n",
    "            print(f\"Page {i+1} - Metadata: {doc.metadata}\")\n",
    "            print(\"-\" * 20)\n",
    "    else:\n",
    "        print(\"No documents loaded from PDF (file might be empty or corrupted).\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading PDF: {e}\")\n",
    "    print(\"Please ensure you have 'pypdf' installed and 'sample.pdf' is a valid PDF file.\")\n",
    "\n",
    "# Clean up sample file\n",
    "os.remove(pdf_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. `WebBaseLoader`: Loading Content from Web Pages\n",
    "\n",
    "* **Concept:** `WebBaseLoader` allows you to load text content from a specific URL. It uses the `BeautifulSoup4` library to parse HTML and extract relevant text.\n",
    "* **When to Use:** When you need to retrieve information from public web pages, blog posts, or online documentation.\n",
    "* **Requirement:** Requires the `BeautifulSoup4` library: `pip install beautifulsoup4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if not already installed:\n",
    "# pip install beautifulsoup4 langchain\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Initialize WebBaseLoader with a URL\n",
    "# Use a public and stable URL for illustration\n",
    "url = \"https://www.langchain.com/blog/langchain-expression-language\"\n",
    "loader = WebBaseLoader(url)\n",
    "\n",
    "try:\n",
    "    # Load documents from URL\n",
    "    documents_web = loader.load()\n",
    "\n",
    "    print(f\"--- Content from WebBaseLoader ({url}) ---\")\n",
    "    if documents_web:\n",
    "        for doc in documents_web:\n",
    "            print(f\"Content (partial): {doc.page_content[:200]}...\")\n",
    "            print(f\"Metadata: {doc.metadata}\")\n",
    "            print(\"-\" * 20)\n",
    "    else:\n",
    "        print(\"No documents loaded from URL.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading from web: {e}\")\n",
    "    print(\"Please check internet connection and valid URL.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. `CSVLoader`: Loading Data from CSV Files\n",
    "\n",
    "* **Concept:** `CSVLoader` loads data from CSV files. Each row in the CSV file can be converted into a separate `Document` object, or you can specify a particular column as the main content and other columns as metadata.\n",
    "* **When to Use:** When you have structured tabular data in CSV files and want to bring it into LangChain.\n",
    "* **Requirement:** No special dependencies beyond `langchain` for the basic `CSVLoader`. However, if you use `UnstructuredCSVLoader`, you would need `pip install unstructured`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if not already installed:\n",
    "# pip install langchain\n",
    "\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "import os\n",
    "\n",
    "# Create a sample CSV file\n",
    "csv_file_path = \"sample.csv\"\n",
    "with open(csv_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"ID,Product Name,Description,Price\\n\")\n",
    "    f.write(\"1,Gaming Laptop,Powerful laptop for gamers,1500\\n\")\n",
    "    f.write(\"2,Mechanical Keyboard,Keyboard with RGB lighting and mechanical switches,120\\n\")\n",
    "    f.write(\"3,Wireless Mouse,Lightweight and precise mouse,50\\n\")\n",
    "\n",
    "# Initialize CSVLoader and load documents\n",
    "# You can specify column_for_content if you want a specific column as page_content\n",
    "loader = CSVLoader(csv_file_path, encoding=\"utf-8\")\n",
    "documents_csv = loader.load()\n",
    "\n",
    "print(f\"--- Content from CSVLoader ({csv_file_path}) ---\")\n",
    "for doc in documents_csv:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "# Clean up sample file\n",
    "os.remove(csv_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Other Loaders (Optional): Google Drive, Notion, YouTube, etc.\n",
    "\n",
    "LangChain supports a wide array of Document Loaders for other diverse data sources, including:\n",
    "\n",
    "* **Cloud Storage:** `GoogleDriveLoader`, `S3DirectoryLoader` (Amazon S3), `AzureBlobStorageContainerLoader`.\n",
    "* **Productivity Tools:** `NotionDirectoryLoader`, `ConfluenceLoader`.\n",
    "* **Multimedia:** `YoutubeLoader` (extracts subtitles), `AssemblyAIAudioTranscriptLoader`.\n",
    "* **Databases:** `PostgresLoader`, `MongoDBLoader`, `SQLAlchemyLoader`.\n",
    "* **Other File Formats:** `UnstructuredFileLoader` (for complex formats like DOCX, PPTX), `EvernoteLoader`.\n",
    "\n",
    "Using these loaders is similar to the examples above, often requiring additional Python libraries specific to each data source (e.g., `google-api-python-client` for Google Drive, `notion-client` for Notion).\n",
    "\n",
    "You can find a complete list and detailed instructions for each loader in the official LangChain documentation: [https://python.langchain.com/docs/modules/data_connection/document_loaders/](https://python.langchain.com/docs/modules/data_connection/document_loaders/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Practical Example: Loading Data from Various Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, let's consider a scenario where we need to load data from multiple different sources and process them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all necessary libraries for this example\n",
    "# pip install langchain pypdf beautifulsoup4 reportlab\n",
    "\n",
    "import os\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader, WebBaseLoader, CSVLoader\n",
    "\n",
    "# --- Prepare sample files ---\n",
    "# TXT File\n",
    "txt_content = \"This is important information from a text note.\\nIt talks about the benefits of learning programming.\"\n",
    "with open(\"note.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(txt_content)\n",
    "\n",
    "# CSV File\n",
    "csv_content = \"Product,Price,Quantity\\nLaptop,1200,50\\nPhone,800,120\\nHeadphones,50,300\"\n",
    "with open(\"products.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(csv_content)\n",
    "\n",
    "# PDF File (dummy, you need to replace with a real PDF for content)\n",
    "# For simplicity, create an empty file if no real PDF is available\n",
    "pdf_test_path = \"document.pdf\"\n",
    "try:\n",
    "    # Try to create a simple PDF using reportlab if available\n",
    "    from reportlab.pdfgen import canvas\n",
    "    c = canvas.Canvas(pdf_test_path)\n",
    "    c.drawString(100, 750, \"This is content from a sample PDF file.\")\n",
    "    c.drawString(100, 730, \"It is generated for illustration purposes.\")\n",
    "    c.save()\n",
    "except ImportError:\n",
    "    with open(pdf_test_path, \"w\") as f:\n",
    "        f.write(\"This is a dummy PDF file. Please replace with a real PDF.\\n\")\n",
    "    print(\"Could not create real PDF. Using dummy file.\")\n",
    "\n",
    "\n",
    "# --- Load data using different loaders ---\n",
    "\n",
    "all_documents = []\n",
    "\n",
    "# 1. Load from TXT\n",
    "print(\"Loading from note.txt...\")\n",
    "txt_loader = TextLoader(\"note.txt\", encoding=\"utf-8\")\n",
    "all_documents.extend(txt_loader.load())\n",
    "\n",
    "# 2. Load from CSV\n",
    "print(\"Loading from products.csv...\")\n",
    "csv_loader = CSVLoader(\"products.csv\", encoding=\"utf-8\")\n",
    "all_documents.extend(csv_loader.load())\n",
    "\n",
    "# 3. Load from Web (using a public URL)\n",
    "print(\"Loading from a web page...\")\n",
    "web_loader = WebBaseLoader(\"https://www.langchain.com/blog\")\n",
    "try:\n",
    "    all_documents.extend(web_loader.load())\n",
    "except Exception as e:\n",
    "    print(f\"Error loading from web: {e}. Skipping web load.\")\n",
    "\n",
    "# 4. Load from PDF\n",
    "print(\"Loading from document.pdf...\")\n",
    "try:\n",
    "    pdf_loader = PyPDFLoader(pdf_test_path)\n",
    "    all_documents.extend(pdf_loader.load())\n",
    "except Exception as e:\n",
    "    print(f\"Error loading from PDF: {e}. Skipping PDF load.\")\n",
    "\n",
    "\n",
    "print(\"\\n--- All loaded documents ---\")\n",
    "for i, doc in enumerate(all_documents):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(f\"  Source: {doc.metadata.get('source', 'Unknown')}\")\n",
    "    print(f\"  Content (partial): {doc.page_content[:150]}...\")\n",
    "    print(f\"  Metadata: {doc.metadata}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "# --- Clean up sample files ---\n",
    "os.remove(\"note.txt\")\n",
    "os.remove(\"products.csv\")\n",
    "os.remove(pdf_test_path)\n",
    "print(\"\\nSample files removed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "This example illustrates how you can use various Document Loaders to collect data from diverse sources into a unified list of `Document` objects. This sets the stage for subsequent processing steps like text splitting and embedding generation, which are fundamental to RAG applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Summary\n",
    "\n",
    "This lesson introduced **Document Loaders** in LangChain, essential tools for loading data from external sources into the **`Document`** format that LangChain can process. We learned about the structure of the `Document` object (consisting of `page_content` and `metadata`) and the importance of Document Loaders in integrating diverse data and building RAG systems. The lesson also delved into common Document Loader types such as **`TextLoader`**, **`PyPDFLoader`**, **`WebBaseLoader`**, and **`CSVLoader`**, along with specific practical examples for each. Finally, a comprehensive example illustrated how to load data from multiple formats into a unified processing flow, laying the groundwork for building more complex LLM applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
